<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>PyTorch源码阅读:Tensor的COW机制</title>
    <link href="/2025/02/12/PyTorch%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-Tensor%E7%9A%84COW%E6%9C%BA%E5%88%B6/"/>
    <url>/2025/02/12/PyTorch%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-Tensor%E7%9A%84COW%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="〇、背景"><a href="#〇、背景" class="headerlink" title="〇、背景"></a>〇、背景</h1><p>COW(copy on write)是一种常用的节约内存的手段：当要制作一个对象的副本时，先不做deep-copy，而是用某种方法使副本与原件共享存储，当其中一个对象要被修改时再做拷贝，可以认为是一种lazy的拷贝模式。PyTorch中的Tensor也实现了这个机制，只是截止2.4版本，还没有大规模应用。但了解一下这个特性，也会给我们对pytorch的开发优化提供新思路。</p><h2 id="0x00、Tensor的view和storage"><a href="#0x00、Tensor的view和storage" class="headerlink" title="0x00、Tensor的view和storage"></a>0x00、Tensor的view和storage</h2><p>在看COW机制之前，要先了解下Tensor的内存是如何管理的。pytorch的tensor可以分成两层来看：view和storage。view就是类似于tensor的维度、步长等等属性，view描述了一个tensor的形状，以及如何从内存上取数据，但是其没有维护数据，真正的数据指针被storage保管着。当改变tensor的形状时，有些情况下只需要修改view，storage根本不需要改变，只要以view指定的取数模式去访问内存，就可以得到目标形状的tensor，因此几个不同view的tensor可能共享同一个storage。关于view的东西也可以讲很多，已经偏离了本文的主题，有兴趣可以查阅资料或者阅读源码。</p><p>storage如何维护真正的内存，是COW机制的背景，需要分析一下，直接上源码吧。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">C10_API</span> StorageImpl : <span class="hljs-keyword">public</span> c10::intrusive_ptr_target &#123;<br>  DataPtr data_ptr_;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>StorageImpl</code>类是<code>Storage</code>的实现类，其中有一个<code>DataPtr</code>，就是维护DDR数据指针的结构，访存的时候都要通过它。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">C10_API</span> DataPtr &#123;<br> <span class="hljs-keyword">private</span>:<br>  c10::detail::UniqueVoidPtr ptr_;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">UniqueVoidPtr</span> &#123;<br> <span class="hljs-keyword">private</span>:<br>  <span class="hljs-comment">// Lifetime tied to ctx_</span><br>  <span class="hljs-type">void</span>* data_;<br>  std::unique_ptr&lt;<span class="hljs-type">void</span>, DeleterFnPtr&gt; ctx_;<br><br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-built_in">UniqueVoidPtr</span>() : <span class="hljs-built_in">data_</span>(<span class="hljs-literal">nullptr</span>), <span class="hljs-built_in">ctx_</span>(<span class="hljs-literal">nullptr</span>, &amp;deleteNothing) &#123;&#125;<br>  <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">UniqueVoidPtr</span><span class="hljs-params">(<span class="hljs-type">void</span>* data)</span></span><br><span class="hljs-function">      : data_(data), ctx_(nullptr, &amp;deleteNothing) &#123;</span>&#125;<br>  <span class="hljs-built_in">UniqueVoidPtr</span>(<span class="hljs-type">void</span>* data, <span class="hljs-type">void</span>* ctx, DeleterFnPtr ctx_deleter)<br>      : <span class="hljs-built_in">data_</span>(data), <span class="hljs-built_in">ctx_</span>(ctx, ctx_deleter ? ctx_deleter : &amp;deleteNothing) &#123;&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">deleteNothing</span><span class="hljs-params">(<span class="hljs-type">void</span>*)</span> </span>&#123;&#125;<br></code></pre></td></tr></table></figure><p>Allocator在分配内存后，会构建一个DataPtr，把内存指针填到里面，并且维护一个ctx。这个ctx是一个unique_ptr智能指针，构建时指定了deleter，智能指针中维护着一个与内存指针有关的<code>void*</code>变量。当storage的引用消失，这个unique_ptr被释放时，会调到deleter。一般deleter会根据ctx中存的<code>void*</code>变量，让allocator做对应的内存释放工作。</p><h1 id="I、概述"><a href="#I、概述" class="headerlink" title="I、概述"></a>I、概述</h1><p>本文参考<a href="https://docs.google.com/document/d/1kWIRUeixlgnOk1eXJSsbxOAKUKQFpmz0yzwLZUjWotg/edit?pli=1&tab=t.0#heading=h.u7owworvku1p">Tensor COW提交者的手稿</a>，学习一下COW提出的动机以及实现的思路。</p><h2 id="0x00、提出动机"><a href="#0x00、提出动机" class="headerlink" title="0x00、提出动机"></a>0x00、提出动机</h2><ul><li>reshape()等view类操作，有可能只返回tensor的视图，也有可能返回新的拷贝，这取决于改变size和步幅后，tensor是不是仍然<code>contiguous</code>。现在希望改成确定性的copy，并且在eager模式下还不降低性能；</li><li>为了反向传播，pytorch需要保存tensor，如果在中途被修改了的话，将影响反向传播的结果。如果能在必要的时候将其替换为拷贝，将会解决很多困扰。</li></ul><h2 id="0x01、实现方案"><a href="#0x01、实现方案" class="headerlink" title="0x01、实现方案"></a>0x01、实现方案</h2><p>COW的Storage与其他COW Storage共享同一个数据指针（普通tensor的不同view是共享同一个Storage），当任意一个storage数据要被修改时，就需要拷贝一份新的，称为<code>copy on write</code>。</p><h3 id="0、COW-Tensor创建的情况"><a href="#0、COW-Tensor创建的情况" class="headerlink" title="0、COW Tensor创建的情况"></a>0、COW Tensor创建的情况</h3><ul><li>当一个OP可能返回view，也可能返回拷贝时（如reshape），现在可以强制其返回COW Tensor；</li><li>为了反向传播保存的tensor，可以指定为COW的。</li></ul><h3 id="1、COW-Storage的特性"><a href="#1、COW-Storage的特性" class="headerlink" title="1、COW Storage的特性"></a>1、COW Storage的特性</h3><ul><li>COW是Storage层面的概念而不是tensor的（与view要区分清楚），只有在COW Storage的alias被改写时，才会触发写时拷贝；</li><li>每个不同的Storage在逻辑上都是独立的，就算其因为延迟拷贝共享同一个实际的指针。这与每个普通tensor的storage维护一个自己的数据指针在逻辑上是相同的；</li><li>当写时拷贝发生时，不会区分哪个storage是最原始的存储，被改写的那个storage会被复制。</li></ul><h3 id="2、对于数据结构的修改"><a href="#2、对于数据结构的修改" class="headerlink" title="2、对于数据结构的修改"></a>2、对于数据结构的修改</h3><ul><li>StorageImpl<ul><li>添加一个COW互斥锁，保护allocator context的unique_ptr。</li></ul></li><li>DataPtr<ul><li>CopyOnWriteDeleter：实现一个新的COW deleter，该deleter中有一个引用计数，执行时会减少。只有当引用计数为0时，原本的deleter才会被执行，进行内存释放的逻辑；</li><li>CopyOnWriteContext：<ul><li>维护指向真实数据的指针</li><li>一个原子类型的引用计数，因为COW互斥锁只保护Storage，但是多个Storage会共享一个context</li><li>原本的deleter</li></ul></li></ul></li></ul><h3 id="3、COW如何工作"><a href="#3、COW如何工作" class="headerlink" title="3、COW如何工作"></a>3、COW如何工作</h3><ol><li><p>当你想要把一个已存在的Storage变为COW的时：</p><ul><li>如果这个Storage还不是COW的，使其变成COW；<ul><li>获取这个storage上的cow mutex；</li><li>检查是否已经是cow的，若不是则可以继续创建；</li><li>检查context ptr !&#x3D; data ptr（Allocator::is_simple_data_ptr虚方法，在清楚ctx和data不同的原因和是否应用COW时，可以重写），若成立，说明ctx已经有其他类似的用途，不能继续搞成COW的；</li><li>若可以继续，则分配一个CopyOnWriteContext，替换掉原始的ctx。</li></ul></li><li>创建新的COW storage：<ul><li>增加CopyOnWriteContext的引用计数</li><li>创建新的storage和Dataptr，赋值给CopyOnWriteContext</li></ul></li></ul></li><li><p>当要修改COW storage时：</p><ul><li>如果引用计数为1，则直接使用这个storage（unwrap这个deleter，替换为之前的）；若不是，要重新分配一个数据指针，复制之前的数据到这个指针中（Allocator::copy_data虚方法实现），并且用这个数据指针替换Storage中原来的指针（此操作会触发原指针的deleter，减少引用计数）；</li></ul></li></ol><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202502122226502.png" alt="image-20250212222652473"></p><h1 id="II、源码分析"><a href="#II、源码分析" class="headerlink" title="II、源码分析"></a>II、源码分析</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">C10_API</span> COWDeleterContext &#123;<br> <span class="hljs-keyword">public</span>:<br>  <span class="hljs-function"><span class="hljs-keyword">explicit</span> <span class="hljs-title">COWDeleterContext</span><span class="hljs-params">(std::unique_ptr&lt;<span class="hljs-type">void</span>, DeleterFnPtr&gt; data)</span></span>;<br><br>  <span class="hljs-keyword">using</span> NotLastReference = std::shared_lock&lt;std::shared_mutex&gt;;<br>  <span class="hljs-keyword">using</span> LastReference = std::unique_ptr&lt;<span class="hljs-type">void</span>, DeleterFnPtr&gt;;<br><br>  <span class="hljs-function">std::variant&lt;NotLastReference, LastReference&gt; <span class="hljs-title">decrement_refcount</span><span class="hljs-params">()</span></span>;<br><br> <span class="hljs-keyword">private</span>:<br>  ~<span class="hljs-built_in">COWDeleterContext</span>();<br><br>  std::shared_mutex mutex_;<br>  std::unique_ptr&lt;<span class="hljs-type">void</span>, DeleterFnPtr&gt; data_;<br>  std::atomic&lt;std::<span class="hljs-type">int64_t</span>&gt; refcount_ = <span class="hljs-number">1</span>;<br>&#125;;<br><br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">cow::cow_deleter</span><span class="hljs-params">(<span class="hljs-type">void</span>* ctx)</span> </span>&#123;<br>  <span class="hljs-built_in">static_cast</span>&lt;cow::COWDeleterContext*&gt;(ctx)-&gt;<span class="hljs-built_in">decrement_refcount</span>();<br>&#125;<br><br>cow::COWDeleterContext::<span class="hljs-built_in">COWDeleterContext</span>(<br>    std::unique_ptr&lt;<span class="hljs-type">void</span>, DeleterFnPtr&gt; data)<br>    : <span class="hljs-built_in">data_</span>(std::<span class="hljs-built_in">move</span>(data)) &#123;<br>  <span class="hljs-comment">// We never wrap a COWDeleterContext.</span><br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(data_.<span class="hljs-built_in">get_deleter</span>() != cow::cow_deleter);<br>&#125;<br><br><span class="hljs-keyword">auto</span> cow::COWDeleterContext::<span class="hljs-built_in">increment_refcount</span>() -&gt; <span class="hljs-type">void</span> &#123;<br>  <span class="hljs-keyword">auto</span> refcount = ++refcount_;<br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(refcount &gt; <span class="hljs-number">1</span>);<br>&#125;<br><br><span class="hljs-keyword">auto</span> cow::COWDeleterContext::<span class="hljs-built_in">decrement_refcount</span>()<br>    -&gt; std::variant&lt;NotLastReference, LastReference&gt; &#123;<br>  <span class="hljs-keyword">auto</span> refcount = --refcount_;<br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(refcount &gt;= <span class="hljs-number">0</span>, refcount);<br>  <span class="hljs-keyword">if</span> (refcount == <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-function">std::unique_lock <span class="hljs-title">lock</span><span class="hljs-params">(mutex_)</span></span>;<br>    <span class="hljs-keyword">auto</span> result = std::<span class="hljs-built_in">move</span>(data_);<br>    lock.<span class="hljs-built_in">unlock</span>();<br>    <span class="hljs-keyword">delete</span> <span class="hljs-keyword">this</span>;<br>    <span class="hljs-keyword">return</span> &#123;std::<span class="hljs-built_in">move</span>(result)&#125;;<br>  &#125;<br><br>  <span class="hljs-keyword">return</span> std::<span class="hljs-built_in">shared_lock</span>(mutex_);<br>&#125;<br><br>cow::COWDeleterContext::~<span class="hljs-built_in">COWDeleterContext</span>() &#123;<br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(refcount_ == <span class="hljs-number">0</span>);<br>&#125;<br><br><span class="hljs-comment">// Wraps a DataPtr with a copy-on-write DataPtr.</span><br><span class="hljs-function">at::DataPtr <span class="hljs-title">make_data_ptr</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    at::DataPtr <span class="hljs-type">const</span>&amp; data_ptr,</span></span><br><span class="hljs-params"><span class="hljs-function">    cow::COWDeleterContext&amp; ctx)</span> </span>&#123;<br>  <span class="hljs-keyword">return</span> at::<span class="hljs-built_in">DataPtr</span>(data_ptr.<span class="hljs-built_in">get</span>(), &amp;ctx, cow::cow_deleter, data_ptr.<span class="hljs-built_in">device</span>());<br>&#125;<br><br><span class="hljs-comment">/// Copies a copy-on-write DataPtr.</span><br><span class="hljs-function">at::DataPtr <span class="hljs-title">copy_data_ptr</span><span class="hljs-params">(at::DataPtr <span class="hljs-type">const</span>&amp; data_ptr)</span> </span>&#123;<br>  <span class="hljs-keyword">auto</span>* ctx = data_ptr.<span class="hljs-built_in">cast_context</span>&lt;cow::COWDeleterContext&gt;(cow::cow_deleter);<br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(ctx != <span class="hljs-literal">nullptr</span>);<br>  ctx-&gt;<span class="hljs-built_in">increment_refcount</span>();<br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">make_data_ptr</span>(data_ptr, *ctx);<br>&#125;<br><br>&#125; <span class="hljs-comment">// namespace</span><br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">has_simple_data_ptr</span><span class="hljs-params">(<span class="hljs-type">const</span> c10::StorageImpl&amp; storage)</span> </span>&#123;<br>  <span class="hljs-type">const</span> c10::DataPtr&amp; data_ptr = storage.<span class="hljs-built_in">data_ptr</span>();<br>  <span class="hljs-type">const</span> <span class="hljs-type">void</span>* ctx = data_ptr.<span class="hljs-built_in">get_context</span>();<br>  <span class="hljs-type">const</span> <span class="hljs-type">void</span>* data = data_ptr.<span class="hljs-built_in">get</span>();<br>  <span class="hljs-type">const</span> c10::Allocator* allocator = storage.<span class="hljs-built_in">allocator</span>();<br>  <span class="hljs-keyword">if</span> (allocator != <span class="hljs-literal">nullptr</span>) &#123;<br>    <span class="hljs-keyword">return</span> allocator-&gt;<span class="hljs-built_in">is_simple_data_ptr</span>(data_ptr);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-keyword">return</span> ctx == data;<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">is_cow_data_ptr</span><span class="hljs-params">(<span class="hljs-type">const</span> c10::DataPtr&amp; data_ptr)</span> </span>&#123;<br>  <span class="hljs-keyword">return</span> (<span class="hljs-type">void</span>*)data_ptr.<span class="hljs-built_in">get_deleter</span>() == (<span class="hljs-type">void</span>*)&amp;cow::cow_deleter;<br>&#125;<br><br><span class="hljs-function">c10::intrusive_ptr&lt;StorageImpl&gt; <span class="hljs-title">lazy_clone_storage</span><span class="hljs-params">(StorageImpl&amp; storage)</span> </span>&#123;<br>  <span class="hljs-type">const</span> at::DataPtr&amp; data_ptr = storage.<span class="hljs-built_in">data_ptr</span>();<br><br>  <span class="hljs-comment">// There are three possible circumstances:</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">// 1) The storage has a normal data pointer with no out of the ordinary</span><br>  <span class="hljs-comment">//    context. In this case we know that there are no blind aliases to the</span><br>  <span class="hljs-comment">//    storage impl: they all will be public aliases and the user is expected</span><br>  <span class="hljs-comment">//    to synchronize manually.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">//    No locking is required in this case.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">// 2) The storage already has a copy on write context. There</span><br>  <span class="hljs-comment">//    is a potential race condition with a blind alias (i.e. an</span><br>  <span class="hljs-comment">//    alias that the user is not required to synchronize</span><br>  <span class="hljs-comment">//    with). Because our input storage is bound to a live reference</span><br>  <span class="hljs-comment">//    to the data, we know that it isn&#x27;t going away. A blind alias</span><br>  <span class="hljs-comment">//    could be copying from it right now, but we will grab the</span><br>  <span class="hljs-comment">//    context&#x27;s mutex to protect us.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">//    We do not need to lock in this case either, because we&#x27;re just</span><br>  <span class="hljs-comment">//    wrapping a context that we know isn&#x27;t going away.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">// 3) The storage has a context that is not the copy on write</span><br>  <span class="hljs-comment">//    context. This is not supported, so we just return null.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">//    No locking is required in this case.</span><br><br>  std::optional&lt;DataPtr&gt; new_data_ptr; <span class="hljs-comment">// must be set below</span><br><br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">has_simple_data_ptr</span>(storage)) &#123;<br>    <span class="hljs-comment">// Case 1) We have a simple data pointer: wrap it.</span><br>    std::unique_ptr&lt;<span class="hljs-type">void</span>, DeleterFnPtr&gt; original_ctx =<br>        storage.<span class="hljs-built_in">mutable_data_ptr</span>().<span class="hljs-built_in">move_context</span>();<br><br>    <span class="hljs-comment">// Save this for the result.</span><br>    new_data_ptr = <span class="hljs-built_in">make_data_ptr</span>(<br>        data_ptr, *<span class="hljs-keyword">new</span> cow::<span class="hljs-built_in">COWDeleterContext</span>(std::<span class="hljs-built_in">move</span>(original_ctx)));<br><br>    <span class="hljs-comment">// Update this storage to the new copy on write context.</span><br>    storage.<span class="hljs-built_in">set_data_ptr_noswap</span>(<span class="hljs-built_in">copy_data_ptr</span>(*new_data_ptr));<br>  &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (<span class="hljs-built_in">is_cow_data_ptr</span>(data_ptr)) &#123;<br>    <span class="hljs-comment">// Case 2): there is already a copy on write context. Just return a</span><br>    <span class="hljs-comment">// new storage impl.</span><br>    new_data_ptr = <span class="hljs-built_in">copy_data_ptr</span>(data_ptr);<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-comment">// Case 3) There is a context and it&#x27;s not copy-on-write. Nothing</span><br>    <span class="hljs-comment">// we can do here.</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>  &#125;<br><br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(new_data_ptr.<span class="hljs-built_in">has_value</span>());<br><br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">make_intrusive</span>&lt;StorageImpl&gt;(<br>      StorageImpl::<span class="hljs-built_in">use_byte_size_t</span>(),<br>      storage.<span class="hljs-built_in">sym_nbytes</span>(),<br>      *std::<span class="hljs-built_in">move</span>(new_data_ptr),<br>      storage.<span class="hljs-built_in">allocator</span>(),<br>      storage.<span class="hljs-built_in">resizable</span>());<br>&#125;<br><br><span class="hljs-function">C10_API <span class="hljs-type">void</span> <span class="hljs-title">materialize_cow_storage</span><span class="hljs-params">(StorageImpl&amp; storage)</span> </span>&#123;<br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(<br>      !c10::ParallelGuard::<span class="hljs-built_in">is_enabled</span>(),<br>      <span class="hljs-string">&quot;Materializing a storage in the loop function of at::parallel_for is forbidden&quot;</span>);<br>  <span class="hljs-type">const</span> at::DataPtr&amp; data_ptr = storage.<span class="hljs-built_in">data_ptr</span>();<br><br>  <span class="hljs-keyword">auto</span>* ctx = data_ptr.<span class="hljs-built_in">cast_context</span>&lt;cow::COWDeleterContext&gt;(cow::cow_deleter);<br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(ctx != <span class="hljs-literal">nullptr</span>);<br><br>  <span class="hljs-keyword">auto</span> result = ctx-&gt;<span class="hljs-built_in">decrement_refcount</span>();<br><br>  <span class="hljs-comment">// This must be set by each branch below.</span><br>  std::optional&lt;DataPtr&gt; new_data_ptr;<br><br>  <span class="hljs-keyword">if</span> (std::<span class="hljs-built_in">holds_alternative</span>&lt;cow::COWDeleterContext::LastReference&gt;(result)) &#123;<br>    <span class="hljs-comment">// This is the only reference to the data. If there were any racing writes,</span><br>    <span class="hljs-comment">// the context ensured they finished before giving us the result.</span><br>    std::unique_ptr&lt;<span class="hljs-type">void</span>, DeleterFnPtr&gt; data =<br>        std::<span class="hljs-built_in">get</span>&lt;cow::COWDeleterContext::LastReference&gt;(std::<span class="hljs-built_in">move</span>(result));<br>    <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(data.<span class="hljs-built_in">get</span>() == data_ptr.<span class="hljs-built_in">get</span>());<br>    new_data_ptr = <span class="hljs-built_in">DataPtr</span>(<br>        data.<span class="hljs-built_in">release</span>(), data_ptr.<span class="hljs-built_in">get</span>(), data.<span class="hljs-built_in">get_deleter</span>(), data_ptr.<span class="hljs-built_in">device</span>());<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(<br>        std::<span class="hljs-built_in">holds_alternative</span>&lt;cow::COWDeleterContext::NotLastReference&gt;(<br>            result));<br>    <span class="hljs-comment">// We don&#x27;t need to consume the result, it&#x27;s just a shared lock ensuring</span><br>    <span class="hljs-comment">// that the data will remain while we copy it.</span><br>    new_data_ptr = storage.<span class="hljs-built_in">allocator</span>()-&gt;<span class="hljs-built_in">clone</span>(data_ptr.<span class="hljs-built_in">get</span>(), storage.<span class="hljs-built_in">nbytes</span>());<br>  &#125;<br><br>  <span class="hljs-built_in">TORCH_INTERNAL_ASSERT</span>(new_data_ptr.<span class="hljs-built_in">has_value</span>());<br>  DataPtr old_data_ptr =<br>      storage.<span class="hljs-built_in">set_data_ptr_no_materialize_cow</span>(*std::<span class="hljs-built_in">move</span>(new_data_ptr));<br>  <span class="hljs-comment">// The refcount of the context was already decremented above. Release the</span><br>  <span class="hljs-comment">// reference to the context so the refcount doesn&#x27;t get decremented again</span><br>  old_data_ptr.<span class="hljs-built_in">release_context</span>();<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Machine_Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch源码学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch源码学习：源码编译</title>
    <link href="/2024/06/16/PyTorch%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"/>
    <url>/2024/06/16/PyTorch%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/</url>
    
    <content type="html"><![CDATA[<p>学习源码的第一步，当然是编译了。无论是调试学习还是修改验证，编译都是必须迈过的坎儿。学习计算机这些年，对于这种大型项目的编译，我是比较怵的，搭个编译环境就已经很困难了，更不要提过程中的各种报错了。好在现在可以在docker中编译，环境崩了咱就推到重来，不至于重装系统了。</p><h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><p>本文使用<a href="https://leimao.github.io/blog/Build-Develop-PyTorch">Lei Mao’s LOG BOOK</a>中提供的docker file，编译的是GPU版本的pytorch 2.1.0，基于ubuntu22.04+cuda12.1+cudnn8，需要查询下你的GPU是否支持：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">nvidia-smi<br></code></pre></td></tr></table></figure><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202406161343199.png" alt="image-20240616112231819"></p><p>这里显示的是安装的GPU驱动最高支持的cuda版本。</p><p>下面正式开始编译吧！</p><h1 id="编译过程"><a href="#编译过程" class="headerlink" title="编译过程"></a>编译过程</h1><p>先创建一个空的工作目录，把本次需要的东西都一股脑儿放里面吧！</p><h2 id="一、构建docker镜像"><a href="#一、构建docker镜像" class="headerlink" title="一、构建docker镜像"></a>一、构建docker镜像</h2><p>首先写个dockerfile，就命名为torch_build.dockerfile，放在工作目录中。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> nvcr.io/nvidia/cuda:<span class="hljs-number">12.1</span>.<span class="hljs-number">1</span>-cudnn8-devel-ubuntu22.<span class="hljs-number">04</span><br> <br><span class="hljs-keyword">ARG</span> CMAKE_VERSION=<span class="hljs-number">3.28</span>.<span class="hljs-number">3</span><br><span class="hljs-keyword">ARG</span> NUM_JOBS=<span class="hljs-number">8</span><br> <br><span class="hljs-keyword">ENV</span> DEBIAN_FRONTEND noninteractive<br> <br><span class="hljs-comment"># Install package dependencies</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; \</span><br><span class="language-bash">    apt-get install -y --no-install-recommends \</span><br><span class="language-bash">        build-essential \</span><br><span class="language-bash">        software-properties-common \</span><br><span class="language-bash">        autoconf \</span><br><span class="language-bash">        automake \</span><br><span class="language-bash">        libtool \</span><br><span class="language-bash">        libssl-dev \</span><br><span class="language-bash">        pkg-config \</span><br><span class="language-bash">        ca-certificates \</span><br><span class="language-bash">        wget \</span><br><span class="language-bash">        git \</span><br><span class="language-bash">        curl \</span><br><span class="language-bash">        libjpeg-dev \</span><br><span class="language-bash">        libpng-dev \</span><br><span class="language-bash">        language-pack-en \</span><br><span class="language-bash">        locales \</span><br><span class="language-bash">        locales-all \</span><br><span class="language-bash">        python3 \</span><br><span class="language-bash">        python3-py \</span><br><span class="language-bash">        python3-dev \</span><br><span class="language-bash">        python3-pip \</span><br><span class="language-bash">        python3-numpy \</span><br><span class="language-bash">        python3-pytest \</span><br><span class="language-bash">        python3-setuptools \</span><br><span class="language-bash">        libprotobuf-dev \</span><br><span class="language-bash">        protobuf-compiler \</span><br><span class="language-bash">        zlib1g-dev \</span><br><span class="language-bash">        swig \</span><br><span class="language-bash">        vim \</span><br><span class="language-bash">        gdb \</span><br><span class="language-bash">        valgrind &amp;&amp; \</span><br><span class="language-bash">    apt-get clean</span><br> <br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">cd</span> /usr/local/bin &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-built_in">ln</span> -s /usr/bin/python3 python &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-built_in">ln</span> -s /usr/bin/pip3 pip &amp;&amp; \</span><br><span class="language-bash">    pip install --upgrade pip setuptools wheel</span><br> <br><span class="hljs-comment"># System locale</span><br><span class="hljs-comment"># Important for UTF-8</span><br><span class="hljs-keyword">ENV</span> LC_ALL en_US.UTF-<span class="hljs-number">8</span><br><span class="hljs-keyword">ENV</span> LANG en_US.UTF-<span class="hljs-number">8</span><br><span class="hljs-keyword">ENV</span> LANGUAGE en_US.UTF-<span class="hljs-number">8</span><br> <br><span class="hljs-comment"># Install CMake</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">cd</span> /tmp &amp;&amp; \</span><br><span class="language-bash">    wget https://github.com/Kitware/CMake/releases/download/v<span class="hljs-variable">$&#123;CMAKE_VERSION&#125;</span>/cmake-<span class="hljs-variable">$&#123;CMAKE_VERSION&#125;</span>.tar.gz &amp;&amp; \</span><br><span class="language-bash">    tar xzf cmake-<span class="hljs-variable">$&#123;CMAKE_VERSION&#125;</span>.tar.gz &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-built_in">cd</span> cmake-<span class="hljs-variable">$&#123;CMAKE_VERSION&#125;</span> &amp;&amp; \</span><br><span class="language-bash">    ./bootstrap &amp;&amp; \</span><br><span class="language-bash">    make -j<span class="hljs-variable">$&#123;NUM_JOBS&#125;</span> &amp;&amp; \</span><br><span class="language-bash">    make install &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-built_in">rm</span> -rf /tmp/*</span><br> <br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">cd</span> /tmp &amp;&amp; \</span><br><span class="language-bash">    wget https://raw.githubusercontent.com/pytorch/pytorch/master/requirements.txt &amp;&amp; \</span><br><span class="language-bash">    pip install -r requirements.txt</span><br> <br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install lintrunner</span><br></code></pre></td></tr></table></figure><p>使用dockerfile构建一个镜像，需要指定使用的cMake版本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">CMAKE_VERSION=3.25.1<br>docker build -f torch_build.dockerfile --build-arg CMAKE_VERSION=$&#123;CMAKE_VERSION&#125; --tag=torch-build:0.0.1 . #敲命令时千万别忘了这个&quot;.&quot;!!<br></code></pre></td></tr></table></figure><p>构建镜像需要下载一堆依赖，网络条件不好的话很可能下载失败，整体时间也比较长。可以考虑换个源（系统的源和docker镜像源）加快下载速度，如果失败次数太多了，就换换网络试试？（言止于此，诸君自斟）</p><h2 id="二、下载pytorch源码"><a href="#二、下载pytorch源码" class="headerlink" title="二、下载pytorch源码"></a>二、下载pytorch源码</h2><p>在工作目录下运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone --recursive https://github.com/pytorch/pytorch<br></code></pre></td></tr></table></figure><p>这条命令会下载pytorch源码以及一些第三方的库。下载源码才是对网络最大的考验，有些库会反复失败失败，但是一定要保证pytorch主体代码下载成功，其他third_party下的库可以等后面再补。</p><p>到github上查看pytorch的tag，选择需要的版本，这里编译的是2.1.0：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git checkout v2.1.0<br></code></pre></td></tr></table></figure><h2 id="三、创建docker容器编译环境"><a href="#三、创建docker容器编译环境" class="headerlink" title="三、创建docker容器编译环境"></a>三、创建docker容器编译环境</h2><p>创建docker容器时，需要把工作目录映射到容器内，并且使用本机的gpu：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">docker run -it --gpus all -v $(pwd):/mnt torch-build:0.0.1<br></code></pre></td></tr></table></figure><blockquote><p>遇到报错<strong>docker: Error response from daemon: could not select device driver “” with capabilities: [[gpu]]</strong></p><p>需要安装nvidia-docker。</p><p>准备好脚本添加nvidia的源：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | \<br>  sudo apt-key add -<br>distribution=$(. /etc/os-release;echo $ID$VERSION_ID)<br>sudo curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | \<br>  sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list<br>sudo apt-get update<br></code></pre></td></tr></table></figure><p>运行以上脚本，然后安装nvidia-container-runtime和nvidia-docker2：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo apt-get install nvidia-container-runtime<br>sudo apt-get install nvidia-docker2<br></code></pre></td></tr></table></figure><p>然后重启docker服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo systemctl restart docker<br></code></pre></td></tr></table></figure><p>之后重新运行docker run命令。</p></blockquote><h2 id="四、配置编译环境"><a href="#四、配置编译环境" class="headerlink" title="四、配置编译环境"></a>四、配置编译环境</h2><p>pytorch官方推荐使用conda管理编译环境，我们也就不折腾了，在docker容器里安装conda，解放一下自己。首先下载conda并准备好conda安装脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">wget https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh #实践这个版本可以编译成功<br></code></pre></td></tr></table></figure><p>安装脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/bash</span><br>apt install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6 &amp;&amp; bash ./Anaconda3-2022.10-Linux-x86_64.sh &amp;&amp; echo -e &#x27;export PATH=&quot;~/anaconda3/bin&quot;:$PATH\nsource ~/anaconda3/bin/activate&#x27; &gt;&gt; ~/.bashrc<br>source ~/.bashrc<br></code></pre></td></tr></table></figure><p>执行脚本后，如果conda环境没有启动，再<code>source ~/.bashrc</code>一次。</p><p>安装好Conda后，创建一个虚拟环境，并激活这个环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda create -n torch_build<br>conda activate torch_build<br></code></pre></td></tr></table></figure><p><strong>进入下载好的pytorch源码目录</strong>，然后pip安装依赖：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install -r requirements.txt<br></code></pre></td></tr></table></figure><p>使用conda安装依赖：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda install cmake ninja<br>conda install pyyaml<br>conda install intel::mkl-static intel::mkl-include<br>conda install -c pytorch magma-cuda*<br></code></pre></td></tr></table></figure><p>一定要确保这些依赖安装成功。</p><p>同步pytorch源码以及其子模块：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">git submodule sync<br>git submodule update --init --recursive<br></code></pre></td></tr></table></figure><p>由于网络原因，可能只下载了一个空文件夹，编译源码的时候会提示你找不到子模块的代码。这时候需要删除提示模块的文件夹，然后重新执行以上两条命令。</p><blockquote><p>遇到报错 <strong>fatal: detected dubious ownership in repository at XXX</strong></p><p>是因为pytorch源代码共享给了docker容器，需要执行以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">git config --global --add safe.directory <span class="hljs-string">&quot;*&quot;</span></span><br></code></pre></td></tr></table></figure></blockquote><h2 id="五、开始编译"><a href="#五、开始编译" class="headerlink" title="五、开始编译"></a>五、开始编译</h2><p>保持在pytorch源代码目录下，进行编译操作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">export CMAKE_PREFIX_PATH=$&#123;CONDA_PREFIX:-&quot;$(dirname $(which conda))/../&quot;&#125;<br>MAX_JOBS=4 DEBUG=1 USE_DISTRIBUTED=0 BUILD_TEST=1 python setup.py develop<br></code></pre></td></tr></table></figure><p>如果编译失败，执行以下命令，然后再重新编译：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python setup.py clean<br></code></pre></td></tr></table></figure><p>setup.py中有很多编译选项，摘列如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Welcome to the PyTorch setup.py.</span><br><span class="hljs-comment"># Environment variables you are probably interested in:</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   DEBUG  添加debug选项编译源码</span><br><span class="hljs-comment">#     build with -O0 and -g (debug symbols)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   REL_WITH_DEB_INFO</span><br><span class="hljs-comment">#     build with optimizations and -g (debug symbols)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_CUSTOM_DEBINFO=&quot;path/to/file1.cpp;path/to/file2.cpp&quot;</span><br><span class="hljs-comment">#     build with debug info only for specified files</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   MAX_JOBS  并发编译数，不要设置太大，会爆内存</span><br><span class="hljs-comment">#     maximum number of compile jobs we should use to compile your code</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_CUDA=0</span><br><span class="hljs-comment">#     disables CUDA build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CFLAGS</span><br><span class="hljs-comment">#     flags to apply to both C and C++ files to be compiled (a quirk of setup.py</span><br><span class="hljs-comment">#     which we have faithfully adhered to in our build system is that CFLAGS</span><br><span class="hljs-comment">#     also applies to C++ files (unless CXXFLAGS is set), in contrast to the</span><br><span class="hljs-comment">#     default behavior of autogoo and cmake build systems.)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CC  指定C/C++编译器</span><br><span class="hljs-comment">#     the C/C++ compiler to use</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Environment variables for feature toggles:</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   DEBUG_CUDA=1</span><br><span class="hljs-comment">#     if used in conjunction with DEBUG or REL_WITH_DEB_INFO, will also</span><br><span class="hljs-comment">#     build CUDA kernels with -lineinfo --source-in-ptx.  Note that</span><br><span class="hljs-comment">#     on CUDA 12 this may cause nvcc to OOM, so this is disabled by default.</span><br><br><span class="hljs-comment">#   USE_CUDNN=0</span><br><span class="hljs-comment">#     disables the cuDNN build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_CUSPARSELT=0</span><br><span class="hljs-comment">#     disables the cuSPARSELt build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_FBGEMM=0</span><br><span class="hljs-comment">#     disables the FBGEMM build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_KINETO=0</span><br><span class="hljs-comment">#     disables usage of libkineto library for profiling</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_NUMPY=0</span><br><span class="hljs-comment">#     disables the NumPy build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BUILD_TEST=0</span><br><span class="hljs-comment">#     disables the test build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MKLDNN=0</span><br><span class="hljs-comment">#     disables use of MKLDNN</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MKLDNN_ACL</span><br><span class="hljs-comment">#     enables use of Compute Library backend for MKLDNN on Arm;</span><br><span class="hljs-comment">#     USE_MKLDNN must be explicitly enabled.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   MKLDNN_CPU_RUNTIME</span><br><span class="hljs-comment">#     MKL-DNN threading mode: TBB or OMP (default)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_STATIC_MKL</span><br><span class="hljs-comment">#     Prefer to link with MKL statically - Unix only</span><br><span class="hljs-comment">#   USE_ITT=0</span><br><span class="hljs-comment">#     disable use of Intel(R) VTune Profiler&#x27;s ITT functionality</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_NNPACK=0</span><br><span class="hljs-comment">#     disables NNPACK build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_QNNPACK=0</span><br><span class="hljs-comment">#     disables QNNPACK build (quantized 8-bit operators)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_DISTRIBUTED=0</span><br><span class="hljs-comment">#     disables distributed (c10d, gloo, mpi, etc.) build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_TENSORPIPE=0</span><br><span class="hljs-comment">#     disables distributed Tensorpipe backend build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_GLOO=0</span><br><span class="hljs-comment">#     disables distributed gloo backend build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MPI=0</span><br><span class="hljs-comment">#     disables distributed MPI backend build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_SYSTEM_NCCL=0</span><br><span class="hljs-comment">#     disables use of system-wide nccl (we will use our submoduled</span><br><span class="hljs-comment">#     copy in third_party/nccl)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_OPENMP=0</span><br><span class="hljs-comment">#     disables use of OpenMP for parallelization</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_FLASH_ATTENTION=0</span><br><span class="hljs-comment">#     disables building flash attention for scaled dot product attention</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MEM_EFF_ATTENTION=0</span><br><span class="hljs-comment">#    disables building memory efficient attention for scaled dot product attention</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BUILD_BINARY</span><br><span class="hljs-comment">#     enables the additional binaries/ build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   ATEN_AVX512_256=TRUE</span><br><span class="hljs-comment">#     ATen AVX2 kernels can use 32 ymm registers, instead of the default 16.</span><br><span class="hljs-comment">#     This option can be used if AVX512 doesn&#x27;t perform well on a machine.</span><br><span class="hljs-comment">#     The FBGEMM library also uses AVX512_256 kernels on Xeon D processors,</span><br><span class="hljs-comment">#     but it also has some (optimized) assembly code.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   PYTORCH_BUILD_VERSION</span><br><span class="hljs-comment">#   PYTORCH_BUILD_NUMBER</span><br><span class="hljs-comment">#     specify the version of PyTorch, rather than the hard-coded version</span><br><span class="hljs-comment">#     in this file; used when we&#x27;re building binaries for distribution</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   TORCH_CUDA_ARCH_LIST</span><br><span class="hljs-comment">#     specify which CUDA architectures to build for.</span><br><span class="hljs-comment">#     ie `TORCH_CUDA_ARCH_LIST=&quot;6.0;7.0&quot;`</span><br><span class="hljs-comment">#     These are not CUDA versions, instead, they specify what</span><br><span class="hljs-comment">#     classes of NVIDIA hardware we should generate PTX for.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   PYTORCH_ROCM_ARCH</span><br><span class="hljs-comment">#     specify which AMD GPU targets to build for.</span><br><span class="hljs-comment">#     ie `PYTORCH_ROCM_ARCH=&quot;gfx900;gfx906&quot;`</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   ONNX_NAMESPACE</span><br><span class="hljs-comment">#     specify a namespace for ONNX built here rather than the hard-coded</span><br><span class="hljs-comment">#     one in this file; needed to build with other frameworks that share ONNX.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BLAS</span><br><span class="hljs-comment">#     BLAS to be used by Caffe2. Can be MKL, Eigen, ATLAS, FlexiBLAS, or OpenBLAS. If set</span><br><span class="hljs-comment">#     then the build will fail if the requested BLAS is not found, otherwise</span><br><span class="hljs-comment">#     the BLAS will be chosen based on what is found on your system.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   MKL_THREADING</span><br><span class="hljs-comment">#     MKL threading mode: SEQ, TBB or OMP (default)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_ROCM_KERNEL_ASSERT=1</span><br><span class="hljs-comment">#     Enable kernel assert in ROCm platform</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Environment variables we respect (these environment variables are</span><br><span class="hljs-comment"># conventional and are often understood/set by other software.)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CUDA_HOME (Linux/OS X)</span><br><span class="hljs-comment">#   CUDA_PATH (Windows)</span><br><span class="hljs-comment">#     specify where CUDA is installed; usually /usr/local/cuda or</span><br><span class="hljs-comment">#     /usr/local/cuda-x.y</span><br><span class="hljs-comment">#   CUDAHOSTCXX</span><br><span class="hljs-comment">#     specify a different compiler than the system one to use as the CUDA</span><br><span class="hljs-comment">#     host compiler for nvcc.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CUDA_NVCC_EXECUTABLE</span><br><span class="hljs-comment">#     Specify a NVCC to use. This is used in our CI to point to a cached nvcc</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CUDNN_LIB_DIR</span><br><span class="hljs-comment">#   CUDNN_INCLUDE_DIR</span><br><span class="hljs-comment">#   CUDNN_LIBRARY</span><br><span class="hljs-comment">#     specify where cuDNN is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   MIOPEN_LIB_DIR</span><br><span class="hljs-comment">#   MIOPEN_INCLUDE_DIR</span><br><span class="hljs-comment">#   MIOPEN_LIBRARY</span><br><span class="hljs-comment">#     specify where MIOpen is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   NCCL_ROOT</span><br><span class="hljs-comment">#   NCCL_LIB_DIR</span><br><span class="hljs-comment">#   NCCL_INCLUDE_DIR</span><br><span class="hljs-comment">#     specify where nccl is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   NVTOOLSEXT_PATH (Windows only)</span><br><span class="hljs-comment">#     specify where nvtoolsext is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   ACL_ROOT_DIR</span><br><span class="hljs-comment">#     specify where Compute Library is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   LIBRARY_PATH</span><br><span class="hljs-comment">#   LD_LIBRARY_PATH</span><br><span class="hljs-comment">#     we will search for libraries in these paths</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   ATEN_THREADING</span><br><span class="hljs-comment">#     ATen parallel backend to use for intra- and inter-op parallelism</span><br><span class="hljs-comment">#     possible values:</span><br><span class="hljs-comment">#       OMP - use OpenMP for intra-op and native backend for inter-op tasks</span><br><span class="hljs-comment">#       NATIVE - use native thread pool for both intra- and inter-op tasks</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_SYSTEM_LIBS (work in progress)</span><br><span class="hljs-comment">#      Use system-provided libraries to satisfy the build dependencies.</span><br><span class="hljs-comment">#      When turned on, the following cmake variables will be toggled as well:</span><br><span class="hljs-comment">#        USE_SYSTEM_CPUINFO=ON USE_SYSTEM_SLEEF=ON BUILD_CUSTOM_PROTOBUF=OFF</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MIMALLOC</span><br><span class="hljs-comment">#      Static link mimalloc into C10, and use mimalloc in alloc_cpu &amp; alloc_free.</span><br><span class="hljs-comment">#      By default, It is only enabled on Windows.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_PRIORITIZED_TEXT_FOR_LD</span><br><span class="hljs-comment">#      Uses prioritized text form cmake/prioritized_text.txt for LD</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BUILD_LIBTORCH_WHL</span><br><span class="hljs-comment">#      Builds libtorch.so and its dependencies as a wheel</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BUILD_PYTHON_ONLY</span><br><span class="hljs-comment">#      Builds pytorch as a wheel using libtorch.so from a seperate wheel</span><br></code></pre></td></tr></table></figure><p>最后编译成功后，可以导入torch试试。</p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202406161343241.png" alt="image-20240616131408327"></p><blockquote><p>遇到报错：<strong>ImportError: {path}&#x2F;libstdc++.so.6: version &#96;GLIBCXX_3.4.30’ not found</strong></p><p>先检查下&#x2F;usr&#x2F;lib下的库支不支持该版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX</span><br></code></pre></td></tr></table></figure><p>如果存在：</p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202406161343285.png" alt="image-20240616131923931"></p><p>则把&#x2F;usr&#x2F;lib下的这个库替换到报错的{path}中。</p></blockquote><h1 id="本机编译"><a href="#本机编译" class="headerlink" title="本机编译"></a>本机编译</h1><p>本机编译的流程与使用docker基本没有区别，只是需要自己安装cuda，另外注意执行<code>conda install -c pytorch magma-cuda*</code>命令时，要指定本机cuda版本，例如cuda12.1就安装<code>magma-cuda121</code>。</p><h1 id="源码调试"><a href="#源码调试" class="headerlink" title="源码调试"></a>源码调试</h1><p>安装vscode，并且安装好c++和python插件，配置launch.json如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-comment">// 使用 IntelliSense 了解相关属性。 </span><br>    <span class="hljs-comment">// 悬停以查看现有属性的描述。</span><br>    <span class="hljs-comment">// 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span><br>    <span class="hljs-attr">&quot;version&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;0.2.0&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;configurations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Python torch debug&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;debugpy&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;request&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;launch&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;program&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;file&#125;&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;console&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integratedTerminal&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;python&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/home/zr/anaconda3/envs/torch_build/bin/python&quot;</span><span class="hljs-punctuation">,</span>  #使用的python解释器路径<br>            <span class="hljs-attr">&quot;justMyCode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CPP Torch debug&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cppdbg&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;request&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;attach&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;program&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/home/zr/anaconda3/envs/torch_build/bin/python&quot;</span><span class="hljs-punctuation">,</span> #同样是python解释器路径，我们其实是在调试CPython里的pytorch c扩展<br>            <span class="hljs-attr">&quot;processId&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;command:pickProcess&#125;&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;MIMode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;gdb&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;setupCommands&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-punctuation">&#123;</span><br>                    <span class="hljs-attr">&quot;description&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Enable pretty-printing for gdb&quot;</span><span class="hljs-punctuation">,</span><br>                    <span class="hljs-attr">&quot;text&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;-enable-pretty-printing&quot;</span><span class="hljs-punctuation">,</span><br>                    <span class="hljs-attr">&quot;ignoreFailures&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><br>                <span class="hljs-punctuation">&#125;</span><br>            <span class="hljs-punctuation">]</span><br>        <br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><ul><li><p>调试python部分：直接启动python调试器</p></li><li><p>调试C++部分：首先正常启动python的调试，然后启动cpp调试，attach到这个python进程上，就可以调试C++代码了。</p></li></ul><blockquote><p>报错<strong>”Authentication is needed to run  &#x2F;usr&#x2F;bin&#x2F;gdb  as the super user”，[Start gdb fail when attach debug a program.(Authentication is needed to run  &#x2F;usr&#x2F;bin&#x2F;gdb’ as the super user)](Authentication is needed to run &#x2F;usr&#x2F;bin&#x2F;gdb as the super user)</strong></p><p>运行gdb默认需要root权限，可以在终端中输入命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">sudo <span class="hljs-built_in">echo</span> 0| sudo <span class="hljs-built_in">tee</span> /proc/sys/kernel/yama/ptrace_scope</span><br></code></pre></td></tr></table></figure></blockquote>]]></content>
    
    
    <categories>
      
      <category>Machine_Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch源码学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TailQ链表队列</title>
    <link href="/2024/03/24/TailQ%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97/"/>
    <url>/2024/03/24/TailQ%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97/</url>
    
    <content type="html"><![CDATA[<h1 id="0、零零零"><a href="#0、零零零" class="headerlink" title="0、零零零"></a>0、零零零</h1><p>最近在看iperf3的源码，发现使用了TailQ作为维护不同协议结构的链表。想到之前在工作中使用tailQ还引发了一些bug，觉得有必要好好整理一下tailQ的相关细节。</p><p>TailQ是一个双向链表，虽然双向链表是一个比较基础的数据结构，但是TailQ的设计还是十分精巧的，既有相当灵活和泛用的使用场景，又不依赖于linux惯用的container_of宏获取节点数据，这个设计思路值得好好琢磨琢磨。</p><h1 id="1、TailQ结构"><a href="#1、TailQ结构" class="headerlink" title="1、TailQ结构"></a>1、TailQ结构</h1><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403241501455.svg" alt="tailq_struct"></p><p>TailQ由一个list head和若干list node两种结构组成：</p><h3 id="TAILQ-HEAD"><a href="#TAILQ-HEAD" class="headerlink" title="TAILQ_HEAD"></a>TAILQ_HEAD</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_HEAD(name, type)                                    \</span><br><span class="hljs-meta">struct name &#123;                                                     \</span><br><span class="hljs-meta">struct type *tqh_first; <span class="hljs-comment">/* first element */</span>                     \</span><br><span class="hljs-meta">struct type **tqh_last; <span class="hljs-comment">/* addr of last next element */</span>         \</span><br><span class="hljs-meta">&#125;                                                              </span><br></code></pre></td></tr></table></figure><p>宏展开后：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">name</span> </span><br><span class="hljs-class">&#123;</span> <br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">type</span> *<span class="hljs-title">tqh_first</span>;</span> <br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">type</span> **<span class="hljs-title">tqh_last</span>;</span>  <br>&#125; <br></code></pre></td></tr></table></figure><p>该宏定义的是TailQ的list head，链表头中有两个type指针。在使用的时候，name是这个tailQ头结构的名字，而type则是链表节点的类型名。尤其要注意的是，thq_last与tqh_first不同，它是一个二重指针，从这里就能看出tailQ和最常见的双向链表不一样，分析使用接口的时候才能更深切的体会其奥妙。</p><h3 id="TAILQ-ENTRY"><a href="#TAILQ-ENTRY" class="headerlink" title="TAILQ_ENTRY"></a>TAILQ_ENTRY</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_ENTRY(type)                                         \</span><br><span class="hljs-meta">struct &#123;                                                          \</span><br><span class="hljs-meta">struct type *tqe_next;  <span class="hljs-comment">/* next element */</span>                      \</span><br><span class="hljs-meta">struct type **tqe_prev; <span class="hljs-comment">/* address of previous next element */</span>  \</span><br><span class="hljs-meta">&#125;  </span><br></code></pre></td></tr></table></figure><p>该宏展开后：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span> <br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">type</span> *<span class="hljs-title">tqe_next</span>;</span> <br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">type</span> **<span class="hljs-title">tqe_prev</span>;</span>  <br>&#125; <br></code></pre></td></tr></table></figure><p>该宏定义的是tailQ节点的结构，和tailQ头的定义对比，可以发现head节点和node节点的结构除了变量名之外是大差不差的。所以head和node节点在经过类型转换后，都可以操作tqh_last指针或tqe_next指针，其效果是一样的，在接口中经常有这两种结构的复用操作。</p><p>定义了结构以后，链表还需要初始化，我们看下tailQ的初始化接口。</p><h3 id="TAILQ-INIT"><a href="#TAILQ-INIT" class="headerlink" title="TAILQ_INIT"></a>TAILQ_INIT</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_INIT(head) do &#123;                                     \</span><br><span class="hljs-meta">TAILQ_FIRST((head)) = NULL;                                     \</span><br><span class="hljs-meta">(head)-&gt;tqh_last = &amp;TAILQ_FIRST((head));                        \</span><br><span class="hljs-meta">&#125; while (0)</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_FIRST(head)       ((head)-&gt;tqh_first)</span><br></code></pre></td></tr></table></figure><p>该宏展开后：</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs livescript"><span class="hljs-keyword">do</span> &#123; <br>  <span class="hljs-function"><span class="hljs-params">(((head))-&gt;tqh_first)</span> = <span class="hljs-params">((<span class="hljs-literal">void</span>*)<span class="hljs-number">0</span>)</span>; </span><br><span class="hljs-function">  <span class="hljs-params">(head)</span>-&gt;</span>tqh_last = &amp;<span class="hljs-function"><span class="hljs-params">(((&amp;testp-&gt;xbind_addrs))-&gt;tqh_first)</span>; </span><br><span class="hljs-function">&#125; <span class="hljs-title">while</span> <span class="hljs-params">(<span class="hljs-number">0</span>)</span></span><br></code></pre></td></tr></table></figure><p>这个操作很好理解，将队列头的first指针置为NULL，last指针指向first域（这就是二级指针的原因，其指向了一个指针），初始化完的链表就如图中所示的空列表状态。</p><p>那列表中如果有其他节点是什么样的状态呢？看图中下面的列表，其有一个列表头和3个节点。我们发现数据不是在tailQ节点结构中的，而是tailQ节点被数据的结构体包含着，这样做的原因是增强数据结构的灵活性和泛用性，linux的大量数据结构都是这么定义的。但tailQ的定义方式与linux的一些数据结构定义还有所不同，没有与数据完全解耦，而是通过给用户开放节点定义的接口，让用户自己把需要的数据包含到节点中。关于这一点想详细了解的同学，可以去翻看linux container_of宏的相关定义。</p><p>根据示意图我们可以总结出tailQ结构的几个特点：</p><ul><li>链表头的tqh_first指针指向列表中第一个节点；链表头的tqh_last指针指向列表最后一个节点的tqe_next域；</li><li>节点的tqe_next指针指向下一个节点；节点的tqe_prev指针指向下一个节点的tqe_next域。</li></ul><p>对比一下，链表头和链表节点的结构基本就是一模一样的，其next指针都指向下一个节点，prev指针都指向上一个节点的next域，而链表头则分别连接链表的第一个节点和最后一个节点。我们再分析一下，可以发现一些隐藏的特点：</p><ul><li>一个节点的tqe_prev节点解引用，就是一个指向自己这个节点的一级指针</li></ul><p>这个特点是tailQ很多接口操作的基础，也是其设计最精妙的所在，理解了这个操作就可以很快的明白其他接口的原理。接口分析比较抽象，结合实际用例更好理解。</p><h1 id="2、TailQ接口"><a href="#2、TailQ接口" class="headerlink" title="2、TailQ接口"></a>2、TailQ接口</h1><p>我们先定义实例节点，linux中的数据结构有很多都是这样定义的，把数据结构包在数据实例之内，以增加数据结构的泛用性（一套数据结构可以用于多种实例）和灵活性（一个数据实例可以包含多种数据结构）。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> &#123;</span><br>    <span class="hljs-type">char</span> var;<br>    TAILQ_ENTRY(Node) link;<br>&#125;;<br></code></pre></td></tr></table></figure><p>展开以后就是这副模样：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> &#123;</span><br>    <span class="hljs-type">char</span> var;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>      Node *tqe_next;<br>      Node **tqe_prev;<br>    &#125; link;<br>&#125;;<br></code></pre></td></tr></table></figure><p>这时我们再定义链表头，要把定义的实例节点类型传进去</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">TAILQ_HEAD(listhead, Node) list_head;<br></code></pre></td></tr></table></figure><p>展开以后也很简单</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">listhead</span> &#123;</span> <br>    Node * tqh_first; <br>    Node ** tqh_last; <br>&#125; list_head;<br></code></pre></td></tr></table></figure><p>再调用一下初始化接口，一个TailQ链表就定义完成了。但是这个链表还是空的，需要调用插入接口添加数据节点。</p><h3 id="TAILQ-INSERT-TAIL"><a href="#TAILQ-INSERT-TAIL" class="headerlink" title="TAILQ_INSERT_TAIL"></a>TAILQ_INSERT_TAIL</h3><p>这个接口是在链表的尾部插入节点，也就是插在最后面，接口调用方式如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">Node * newNode = (Node *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(Node));<br>TAILQ_INSERT_TAIL(list_head, newNode, link);<br></code></pre></td></tr></table></figure><p>展开后比较容易分析插入操作的原理。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">do</span> &#123; <br>  (newNode)-&gt;link.tqe_next = ((<span class="hljs-type">void</span> *)<span class="hljs-number">0</span>); <br>(newNode)-&gt;link.tqe_prev = (list_head)-&gt;tqh_last; <br>*(list_head)-&gt;tqh_last = (newNode); <br>(list_head)-&gt;tqh_last = &amp;(newNode)-&gt;link.tqe_next; <br>&#125; <span class="hljs-keyword">while</span> (<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>tailQ归根结底是一个双向链表，双向链表插入元素无外乎几个重要操作：</p><ol><li>把前驱节点的后继指针和后继节点的前驱指针接在新节点上；</li><li>新节点的前驱指针和后继指针接上对应的节点。</li></ol><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403241937540.svg" alt="tailq_insert_tail"></p><p>尾插操作可以分为四步：</p><ol><li><p>把新节点的next指针置位NULL，这是插入的常规操作；</p></li><li><p>head的tqh_last指针指向的是最后一个节点的tqe_next指针的位置，因此把它赋值给新节点的tqe_prev，就完成了前驱节点的链接。</p></li><li><p>(list_head)-&gt;tqh_last解引用后，就是最后一个节点的tqe_next指针。以图中的结构为例，(list_head)-&gt;tqh_last的初值是0x04300，*(list_head)-&gt;tqh_last &#x3D; (newNode)操作把newNode的地址赋给了0x04300，也即之前链表里最后一个节点的tqe_next指针。这就完成了后继节点的链接。</p></li><li><p>最后更改head节点的tqh_last指针，还是要指向newNode的tqe_next指针。</p></li></ol><p>在列表末尾插入节点的时间复杂度为O(1)，这就是列表头head存在的意义，不需要从头遍历一遍链表才能找到链表的尾部。</p><h3 id="TAILQ-INSERT-HEAD"><a href="#TAILQ-INSERT-HEAD" class="headerlink" title="TAILQ_INSERT_HEAD"></a>TAILQ_INSERT_HEAD</h3><p>tailQ也同样提供了头插的接口：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">Node * newNode = (Node *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(Node));<br>TAILQ_INSERT_HEAD(list_head, newNode, link);<br></code></pre></td></tr></table></figure><p>展开后：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">do</span> &#123;<br>  <span class="hljs-keyword">if</span> (((newNode)-&gt;link.tqe_next = (list_head)-&gt;tqh_first) != <span class="hljs-literal">NULL</span>)<br>(list_head)-&gt;tqh_first-&gt;link.tqe_prev =&amp;(newNode)-&gt;link.tqe_next;<br><span class="hljs-keyword">else</span><br>(list_head)-&gt;tqh_last = &amp;(newNode)-&gt;link.tqe_next;<br>  (list_head)-&gt;tqh_first = (newNode);<br>(newNode)-&gt;link.tqe_prev = &amp;(list_head)-&gt;tqh_first;<br>&#125; <span class="hljs-keyword">while</span> (<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403241944111.svg" alt="tailq_insert_head"></p><ol><li>新结点的next指针指向list_head的tqh_first指针指向的节点a，节点a也是list中的第一个节点。如果这个指针指向的节点a为NULL，那么新节点是在空列表中插入的第一个节点，也就是最后一个节点，list_head的tqh_last指针需要指向新节点的tqe_next域；如果该列表不为空，那么让第一个节点的tqe_pre指针指向新节点的tqe_next域。</li><li>list_head的tqh_first指针指向新节点，宣布谁是list中的第一个节点；</li><li>新节点的tqe_pre指针要指向list_head的tqh_first域。</li></ol><h3 id="TAILQ-INSERT-BEFORE"><a href="#TAILQ-INSERT-BEFORE" class="headerlink" title="TAILQ_INSERT_BEFORE"></a>TAILQ_INSERT_BEFORE</h3><p>该接口用于在指定节点之前插入新节点。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span>TAILQ_INSERT_BEFORE(listelm, elm, field) do &#123;\</span><br><span class="hljs-meta">(elm)-&gt;field.tqe_prev = (listelm)-&gt;field.tqe_prev;\</span><br><span class="hljs-meta">(elm)-&gt;field.tqe_next = (listelm);\</span><br><span class="hljs-meta">*(listelm)-&gt;field.tqe_prev = (elm);\</span><br><span class="hljs-meta">(listelm)-&gt;field.tqe_prev = &amp;(elm)-&gt;field.tqe_next;\</span><br><span class="hljs-meta">&#125; while (0)</span><br></code></pre></td></tr></table></figure><p>tailQ归根结底还是双向链表，插入删除无非是处理好next和pre指针即可。在listelm前插入elm元素，</p><ol><li>新节点前驱指针指向listelm的前驱，新节点后继指针指向listelm。</li><li>一个节点的tqe_prev解引用就是前驱节点指向本节点的指针，把该节点指向了新节点，也就是前驱节点的next指针指向了新节点。</li><li>listelm的前驱节点指向新节点的next域。</li></ol><h3 id="TAILQ-INSERT-AFTER"><a href="#TAILQ-INSERT-AFTER" class="headerlink" title="TAILQ_INSERT_AFTER"></a>TAILQ_INSERT_AFTER</h3><p>该接口用于在给定节点后面插入新节点。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_INSERT_AFTER(head, listelm, elm, field) do &#123;\</span><br><span class="hljs-meta"><span class="hljs-keyword">if</span> (((elm)-&gt;field.tqe_next = (listelm)-&gt;field.tqe_next) != NULL)\</span><br><span class="hljs-meta">(elm)-&gt;field.tqe_next-&gt;field.tqe_prev =\</span><br><span class="hljs-meta">    &amp;(elm)-&gt;field.tqe_next;\</span><br><span class="hljs-meta"><span class="hljs-keyword">else</span>\</span><br><span class="hljs-meta">(head)-&gt;tqh_last = &amp;(elm)-&gt;field.tqe_next;\</span><br><span class="hljs-meta">(listelm)-&gt;field.tqe_next = (elm);\</span><br><span class="hljs-meta">(elm)-&gt;field.tqe_prev = &amp;(listelm)-&gt;field.tqe_next;\</span><br><span class="hljs-meta">&#125; while (0)</span><br></code></pre></td></tr></table></figure><ol><li>新节点next指向目标节点的next节点。</li><li>在节点后面插入也要处理两种情况，若目标节点是最后一个，那么指向新节点next域的就要是head的tqh_last；若不然，则后继节点的pre指向新节点的next。</li><li>目标节点next指向新节点，新节点pre指向目标节点的next域。</li></ol><h3 id="TAILQ-FOREACH"><a href="#TAILQ-FOREACH" class="headerlink" title="TAILQ_FOREACH"></a>TAILQ_FOREACH</h3><p>这个接口用于正向遍历tailQ。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_FOREACH(var, head, field)\</span><br><span class="hljs-meta">for((var) = TAILQ_FIRST(head);\</span><br><span class="hljs-meta">    (var) != TAILQ_END(head);\</span><br><span class="hljs-meta">    (var) = TAILQ_NEXT(var, field))</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_NEXT(elm, field) ((elm)-&gt;field.tqe_next)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span>TAILQ_END(head)NULL</span><br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span> ((var) = (((head))-&gt;tqh_first); (var) != <span class="hljs-literal">NULL</span>; (var) = (((var))-&gt;filed.tqe_next))<br></code></pre></td></tr></table></figure><p>var是要遍历的列表节点对象，用于存储当前操作的节点；head是目标列表的头节点；filed是列表节点在容器中使用的属性名。</p><h3 id="TAILQ-FOREACH-REVERSE"><a href="#TAILQ-FOREACH-REVERSE" class="headerlink" title="TAILQ_FOREACH_REVERSE"></a>TAILQ_FOREACH_REVERSE</h3><p>这个接口用于反向遍历tailQ。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_FOREACH_REVERSE(var, head, headname, field)\</span><br><span class="hljs-meta">for((var) = TAILQ_LAST(head, headname);\</span><br><span class="hljs-meta">    (var) != TAILQ_END(head);\</span><br><span class="hljs-meta">    (var) = TAILQ_PREV(var, headname, field))</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_PREV(elm, headname, field)\</span><br><span class="hljs-meta">(*(((struct headname *)((elm)-&gt;field.tqe_prev))-&gt;tqh_last))</span><br></code></pre></td></tr></table></figure><p>TAILQ_PREV可以理解为pre节点的pre指针再解引用，就是pre节点的pre节点的next指针，解引用后是pre节点的node本体。</p><p>这里有一个地方不是很好理解，就是前向遍历为什么结束判断的TAILQ_END也定义为NULL。其实看tailQ结构图示就很直观了，第一个节点的tqe_prev指针指向list_head，而list_head的last指针指向最后一个节点的tqe_next域，解引用之后正好就是NULL。</p><h1 id="3、使用心得"><a href="#3、使用心得" class="headerlink" title="3、使用心得"></a>3、使用心得</h1><p>tailQ不是线程安全的，这一点上很少会有误用。但是，就算是单线程使用，如果对已经在列表中的元素执行头插，那么正向遍历会有链表成环的风险（如图中橙色的线），反向遍历会有节点被截断丢失，很多时候我们无意中会引发这个问题，在排查的时候最好能尽快反应。</p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403311229394.svg" alt="tailq_dup_head"></p><p>尾插则不会有成环的问题，因为尾插不管正向遍历还是反向遍历，都需要next指针去获得下一个节点，而尾插新节点next指针一定置为了null，所以尾插法只会引起节点丢失。</p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403311308806.svg" alt="tailq_dup_tail"></p>]]></content>
    
    
    <categories>
      
      <category>source_learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>iperf源码学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第一章</title>
    <link href="/2024/03/08/%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
    <url>/2024/03/08/%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p><strong>第一篇博文，就贴一张图吧！</strong></p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403082312389.jpeg" alt="mofang"></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
