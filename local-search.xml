<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>PyTorch源码学习：源码编译</title>
    <link href="/2024/06/16/PyTorch%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/"/>
    <url>/2024/06/16/PyTorch%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/</url>
    
    <content type="html"><![CDATA[<p>学习源码的第一步，当然是编译了。无论是调试学习还是修改验证，编译都是必须迈过的坎儿。学习计算机这些年，对于这种大型项目的编译，我是比较怵的，搭个编译环境就已经很困难了，更不要提过程中的各种报错了。好在现在可以在docker中编译，环境崩了咱就推到重来，不至于重装系统了。</p><h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><p>本文使用<a href="https://leimao.github.io/blog/Build-Develop-PyTorch/%E4%B8%AD%E6%8F%90%E4%BE%9B%E7%9A%84docker">https://leimao.github.io/blog/Build-Develop-PyTorch/中提供的docker</a> file，编译的是GPU版本的pytorch 2.1.0，基于ubuntu22.04+cuda12.1+cudnn8，需要查询下你的GPU是否支持：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">nvidia-smi<br></code></pre></td></tr></table></figure><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202406161343199.png" alt="image-20240616112231819"></p><p>这里显示的是安装的GPU驱动最高支持的cuda版本。</p><p>下面正式开始编译吧！</p><h1 id="编译过程"><a href="#编译过程" class="headerlink" title="编译过程"></a>编译过程</h1><p>先创建一个空的工作目录，把本次需要的东西都一股脑儿放里面吧！</p><h2 id="一、构建docker镜像"><a href="#一、构建docker镜像" class="headerlink" title="一、构建docker镜像"></a>一、构建docker镜像</h2><p>首先写个dockerfile，就命名为torch_build.dockerfile，放在工作目录中。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> nvcr.io/nvidia/cuda:<span class="hljs-number">12.1</span>.<span class="hljs-number">1</span>-cudnn8-devel-ubuntu22.<span class="hljs-number">04</span><br> <br><span class="hljs-keyword">ARG</span> CMAKE_VERSION=<span class="hljs-number">3.28</span>.<span class="hljs-number">3</span><br><span class="hljs-keyword">ARG</span> NUM_JOBS=<span class="hljs-number">8</span><br> <br><span class="hljs-keyword">ENV</span> DEBIAN_FRONTEND noninteractive<br> <br><span class="hljs-comment"># Install package dependencies</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; \</span><br><span class="language-bash">    apt-get install -y --no-install-recommends \</span><br><span class="language-bash">        build-essential \</span><br><span class="language-bash">        software-properties-common \</span><br><span class="language-bash">        autoconf \</span><br><span class="language-bash">        automake \</span><br><span class="language-bash">        libtool \</span><br><span class="language-bash">        libssl-dev \</span><br><span class="language-bash">        pkg-config \</span><br><span class="language-bash">        ca-certificates \</span><br><span class="language-bash">        wget \</span><br><span class="language-bash">        git \</span><br><span class="language-bash">        curl \</span><br><span class="language-bash">        libjpeg-dev \</span><br><span class="language-bash">        libpng-dev \</span><br><span class="language-bash">        language-pack-en \</span><br><span class="language-bash">        locales \</span><br><span class="language-bash">        locales-all \</span><br><span class="language-bash">        python3 \</span><br><span class="language-bash">        python3-py \</span><br><span class="language-bash">        python3-dev \</span><br><span class="language-bash">        python3-pip \</span><br><span class="language-bash">        python3-numpy \</span><br><span class="language-bash">        python3-pytest \</span><br><span class="language-bash">        python3-setuptools \</span><br><span class="language-bash">        libprotobuf-dev \</span><br><span class="language-bash">        protobuf-compiler \</span><br><span class="language-bash">        zlib1g-dev \</span><br><span class="language-bash">        swig \</span><br><span class="language-bash">        vim \</span><br><span class="language-bash">        gdb \</span><br><span class="language-bash">        valgrind &amp;&amp; \</span><br><span class="language-bash">    apt-get clean</span><br> <br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">cd</span> /usr/local/bin &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-built_in">ln</span> -s /usr/bin/python3 python &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-built_in">ln</span> -s /usr/bin/pip3 pip &amp;&amp; \</span><br><span class="language-bash">    pip install --upgrade pip setuptools wheel</span><br> <br><span class="hljs-comment"># System locale</span><br><span class="hljs-comment"># Important for UTF-8</span><br><span class="hljs-keyword">ENV</span> LC_ALL en_US.UTF-<span class="hljs-number">8</span><br><span class="hljs-keyword">ENV</span> LANG en_US.UTF-<span class="hljs-number">8</span><br><span class="hljs-keyword">ENV</span> LANGUAGE en_US.UTF-<span class="hljs-number">8</span><br> <br><span class="hljs-comment"># Install CMake</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">cd</span> /tmp &amp;&amp; \</span><br><span class="language-bash">    wget https://github.com/Kitware/CMake/releases/download/v<span class="hljs-variable">$&#123;CMAKE_VERSION&#125;</span>/cmake-<span class="hljs-variable">$&#123;CMAKE_VERSION&#125;</span>.tar.gz &amp;&amp; \</span><br><span class="language-bash">    tar xzf cmake-<span class="hljs-variable">$&#123;CMAKE_VERSION&#125;</span>.tar.gz &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-built_in">cd</span> cmake-<span class="hljs-variable">$&#123;CMAKE_VERSION&#125;</span> &amp;&amp; \</span><br><span class="language-bash">    ./bootstrap &amp;&amp; \</span><br><span class="language-bash">    make -j<span class="hljs-variable">$&#123;NUM_JOBS&#125;</span> &amp;&amp; \</span><br><span class="language-bash">    make install &amp;&amp; \</span><br><span class="language-bash">    <span class="hljs-built_in">rm</span> -rf /tmp/*</span><br> <br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">cd</span> /tmp &amp;&amp; \</span><br><span class="language-bash">    wget https://raw.githubusercontent.com/pytorch/pytorch/master/requirements.txt &amp;&amp; \</span><br><span class="language-bash">    pip install -r requirements.txt</span><br> <br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install lintrunner</span><br></code></pre></td></tr></table></figure><p>使用dockerfile构建一个镜像，需要指定使用的cMake版本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">CMAKE_VERSION=3.25.1<br>docker build -f torch_build.dockerfile --build-arg CMAKE_VERSION=$&#123;CMAKE_VERSION&#125; --tag=torch-build:0.0.1 . #敲命令时千万别忘了这个&quot;.&quot;!!<br></code></pre></td></tr></table></figure><p>构建镜像需要下载一堆依赖，网络条件不好的话很可能下载失败，整体时间也比较长。可以考虑换个源（系统的源和docker镜像源）加快下载速度，如果失败次数太多了，就换换网络试试？（言止于此，诸君自斟）</p><h2 id="二、下载pytorch源码"><a href="#二、下载pytorch源码" class="headerlink" title="二、下载pytorch源码"></a>二、下载pytorch源码</h2><p>在工作目录下运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git clone --recursive https://github.com/pytorch/pytorch<br></code></pre></td></tr></table></figure><p>这条命令会下载pytorch源码以及一些第三方的库。下载源码才是对网络最大的考验，有些库会反复失败失败，但是一定要保证pytorch主体代码下载成功，其他third_party下的库可以等后面再补。</p><h2 id="三、创建docker容器编译环境"><a href="#三、创建docker容器编译环境" class="headerlink" title="三、创建docker容器编译环境"></a>三、创建docker容器编译环境</h2><p>创建docker容器时，需要把工作目录映射到容器内，并且使用本机的gpu：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">docker run -it --gpus all -v $(pwd):/mnt torch-build:0.0.1<br></code></pre></td></tr></table></figure><blockquote><p>遇到报错<strong>docker: Error response from daemon: could not select device driver “” with capabilities: [[gpu]]</strong></p><p>需要安装nvidia-docker。</p><p>准备好脚本添加nvidia的源：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | \<br>  sudo apt-key add -<br>distribution=$(. /etc/os-release;echo $ID$VERSION_ID)<br>sudo curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | \<br>  sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list<br>sudo apt-get update<br></code></pre></td></tr></table></figure><p>运行以上脚本，然后安装nvidia-container-runtime和nvidia-docker2：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo apt-get install nvidia-container-runtime<br>sudo apt-get install nvidia-docker2<br></code></pre></td></tr></table></figure><p>然后重启docker服务：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo systemctl restart docker<br></code></pre></td></tr></table></figure><p>之后重新运行docker run命令。</p></blockquote><h2 id="四、配置编译环境"><a href="#四、配置编译环境" class="headerlink" title="四、配置编译环境"></a>四、配置编译环境</h2><p>pytorch官方推荐使用conda管理编译环境，我们也就不折腾了，在docker容器里安装conda，解放一下自己。首先下载conda并准备好conda安装脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">wget https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh #实践这个版本可以编译成功<br></code></pre></td></tr></table></figure><p>安装脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/bash</span><br>apt install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6 &amp;&amp; bash ./Anaconda3-2022.10-Linux-x86_64.sh &amp;&amp; echo -e &#x27;export PATH=&quot;~/anaconda3/bin&quot;:$PATH\nsource ~/anaconda3/bin/activate&#x27; &gt;&gt; ~/.bashrc<br>source ~/.bashrc<br></code></pre></td></tr></table></figure><p>执行脚本后，如果conda环境没有启动，再<code>source ~/.bashrc</code>一次。</p><p>安装好Conda后，创建一个虚拟环境，并激活这个环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda create -n torch_build<br>conda activate torch_build<br></code></pre></td></tr></table></figure><p><strong>进入下载好的pytorch源码目录</strong>，然后pip安装依赖：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install -r requirements.txt<br></code></pre></td></tr></table></figure><p>使用conda安装依赖：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda install cmake ninja<br>conda install pyyaml<br>conda install intel::mkl-static intel::mkl-include<br>conda install -c pytorch magma-cuda*<br></code></pre></td></tr></table></figure><p>一定要确保这些依赖安装成功。</p><p>同步pytorch源码以及其子模块：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">git submodule sync<br>git submodule update --init --recursive<br></code></pre></td></tr></table></figure><p>由于网络原因，可能只下载了一个空文件夹，编译源码的时候会提示你找不到子模块的代码。这时候需要删除提示模块的文件夹，然后重新执行以上两条命令。</p><blockquote><p>遇到报错 <strong>fatal: detected dubious ownership in repository at XXX</strong></p><p>是因为pytorch源代码共享给了docker容器，需要执行以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">git config --global --add safe.directory <span class="hljs-string">&quot;*&quot;</span></span><br></code></pre></td></tr></table></figure></blockquote><h2 id="五、开始编译"><a href="#五、开始编译" class="headerlink" title="五、开始编译"></a>五、开始编译</h2><p>保持在pytorch源代码目录下，进行编译操作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">export CMAKE_PREFIX_PATH=$&#123;CONDA_PREFIX:-&quot;$(dirname $(which conda))/../&quot;&#125;<br>MAX_JOBS=4 DEBUG=1 USE_DISTRIBUTED=0 BUILD_TEST=1 python setup.py develop<br></code></pre></td></tr></table></figure><p>如果编译失败，执行以下命令，然后再重新编译：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python setup.py clean<br></code></pre></td></tr></table></figure><p>setup.py中有很多编译选项，摘列如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Welcome to the PyTorch setup.py.</span><br><span class="hljs-comment"># Environment variables you are probably interested in:</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   DEBUG  添加debug选项编译源码</span><br><span class="hljs-comment">#     build with -O0 and -g (debug symbols)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   REL_WITH_DEB_INFO</span><br><span class="hljs-comment">#     build with optimizations and -g (debug symbols)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_CUSTOM_DEBINFO=&quot;path/to/file1.cpp;path/to/file2.cpp&quot;</span><br><span class="hljs-comment">#     build with debug info only for specified files</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   MAX_JOBS  并发编译数，不要设置太大，会爆内存</span><br><span class="hljs-comment">#     maximum number of compile jobs we should use to compile your code</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_CUDA=0</span><br><span class="hljs-comment">#     disables CUDA build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CFLAGS</span><br><span class="hljs-comment">#     flags to apply to both C and C++ files to be compiled (a quirk of setup.py</span><br><span class="hljs-comment">#     which we have faithfully adhered to in our build system is that CFLAGS</span><br><span class="hljs-comment">#     also applies to C++ files (unless CXXFLAGS is set), in contrast to the</span><br><span class="hljs-comment">#     default behavior of autogoo and cmake build systems.)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CC  指定C/C++编译器</span><br><span class="hljs-comment">#     the C/C++ compiler to use</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Environment variables for feature toggles:</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   DEBUG_CUDA=1</span><br><span class="hljs-comment">#     if used in conjunction with DEBUG or REL_WITH_DEB_INFO, will also</span><br><span class="hljs-comment">#     build CUDA kernels with -lineinfo --source-in-ptx.  Note that</span><br><span class="hljs-comment">#     on CUDA 12 this may cause nvcc to OOM, so this is disabled by default.</span><br><br><span class="hljs-comment">#   USE_CUDNN=0</span><br><span class="hljs-comment">#     disables the cuDNN build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_CUSPARSELT=0</span><br><span class="hljs-comment">#     disables the cuSPARSELt build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_FBGEMM=0</span><br><span class="hljs-comment">#     disables the FBGEMM build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_KINETO=0</span><br><span class="hljs-comment">#     disables usage of libkineto library for profiling</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_NUMPY=0</span><br><span class="hljs-comment">#     disables the NumPy build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BUILD_TEST=0</span><br><span class="hljs-comment">#     disables the test build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MKLDNN=0</span><br><span class="hljs-comment">#     disables use of MKLDNN</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MKLDNN_ACL</span><br><span class="hljs-comment">#     enables use of Compute Library backend for MKLDNN on Arm;</span><br><span class="hljs-comment">#     USE_MKLDNN must be explicitly enabled.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   MKLDNN_CPU_RUNTIME</span><br><span class="hljs-comment">#     MKL-DNN threading mode: TBB or OMP (default)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_STATIC_MKL</span><br><span class="hljs-comment">#     Prefer to link with MKL statically - Unix only</span><br><span class="hljs-comment">#   USE_ITT=0</span><br><span class="hljs-comment">#     disable use of Intel(R) VTune Profiler&#x27;s ITT functionality</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_NNPACK=0</span><br><span class="hljs-comment">#     disables NNPACK build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_QNNPACK=0</span><br><span class="hljs-comment">#     disables QNNPACK build (quantized 8-bit operators)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_DISTRIBUTED=0</span><br><span class="hljs-comment">#     disables distributed (c10d, gloo, mpi, etc.) build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_TENSORPIPE=0</span><br><span class="hljs-comment">#     disables distributed Tensorpipe backend build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_GLOO=0</span><br><span class="hljs-comment">#     disables distributed gloo backend build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MPI=0</span><br><span class="hljs-comment">#     disables distributed MPI backend build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_SYSTEM_NCCL=0</span><br><span class="hljs-comment">#     disables use of system-wide nccl (we will use our submoduled</span><br><span class="hljs-comment">#     copy in third_party/nccl)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_OPENMP=0</span><br><span class="hljs-comment">#     disables use of OpenMP for parallelization</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_FLASH_ATTENTION=0</span><br><span class="hljs-comment">#     disables building flash attention for scaled dot product attention</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MEM_EFF_ATTENTION=0</span><br><span class="hljs-comment">#    disables building memory efficient attention for scaled dot product attention</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BUILD_BINARY</span><br><span class="hljs-comment">#     enables the additional binaries/ build</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   ATEN_AVX512_256=TRUE</span><br><span class="hljs-comment">#     ATen AVX2 kernels can use 32 ymm registers, instead of the default 16.</span><br><span class="hljs-comment">#     This option can be used if AVX512 doesn&#x27;t perform well on a machine.</span><br><span class="hljs-comment">#     The FBGEMM library also uses AVX512_256 kernels on Xeon D processors,</span><br><span class="hljs-comment">#     but it also has some (optimized) assembly code.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   PYTORCH_BUILD_VERSION</span><br><span class="hljs-comment">#   PYTORCH_BUILD_NUMBER</span><br><span class="hljs-comment">#     specify the version of PyTorch, rather than the hard-coded version</span><br><span class="hljs-comment">#     in this file; used when we&#x27;re building binaries for distribution</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   TORCH_CUDA_ARCH_LIST</span><br><span class="hljs-comment">#     specify which CUDA architectures to build for.</span><br><span class="hljs-comment">#     ie `TORCH_CUDA_ARCH_LIST=&quot;6.0;7.0&quot;`</span><br><span class="hljs-comment">#     These are not CUDA versions, instead, they specify what</span><br><span class="hljs-comment">#     classes of NVIDIA hardware we should generate PTX for.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   PYTORCH_ROCM_ARCH</span><br><span class="hljs-comment">#     specify which AMD GPU targets to build for.</span><br><span class="hljs-comment">#     ie `PYTORCH_ROCM_ARCH=&quot;gfx900;gfx906&quot;`</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   ONNX_NAMESPACE</span><br><span class="hljs-comment">#     specify a namespace for ONNX built here rather than the hard-coded</span><br><span class="hljs-comment">#     one in this file; needed to build with other frameworks that share ONNX.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BLAS</span><br><span class="hljs-comment">#     BLAS to be used by Caffe2. Can be MKL, Eigen, ATLAS, FlexiBLAS, or OpenBLAS. If set</span><br><span class="hljs-comment">#     then the build will fail if the requested BLAS is not found, otherwise</span><br><span class="hljs-comment">#     the BLAS will be chosen based on what is found on your system.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   MKL_THREADING</span><br><span class="hljs-comment">#     MKL threading mode: SEQ, TBB or OMP (default)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_ROCM_KERNEL_ASSERT=1</span><br><span class="hljs-comment">#     Enable kernel assert in ROCm platform</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Environment variables we respect (these environment variables are</span><br><span class="hljs-comment"># conventional and are often understood/set by other software.)</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CUDA_HOME (Linux/OS X)</span><br><span class="hljs-comment">#   CUDA_PATH (Windows)</span><br><span class="hljs-comment">#     specify where CUDA is installed; usually /usr/local/cuda or</span><br><span class="hljs-comment">#     /usr/local/cuda-x.y</span><br><span class="hljs-comment">#   CUDAHOSTCXX</span><br><span class="hljs-comment">#     specify a different compiler than the system one to use as the CUDA</span><br><span class="hljs-comment">#     host compiler for nvcc.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CUDA_NVCC_EXECUTABLE</span><br><span class="hljs-comment">#     Specify a NVCC to use. This is used in our CI to point to a cached nvcc</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   CUDNN_LIB_DIR</span><br><span class="hljs-comment">#   CUDNN_INCLUDE_DIR</span><br><span class="hljs-comment">#   CUDNN_LIBRARY</span><br><span class="hljs-comment">#     specify where cuDNN is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   MIOPEN_LIB_DIR</span><br><span class="hljs-comment">#   MIOPEN_INCLUDE_DIR</span><br><span class="hljs-comment">#   MIOPEN_LIBRARY</span><br><span class="hljs-comment">#     specify where MIOpen is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   NCCL_ROOT</span><br><span class="hljs-comment">#   NCCL_LIB_DIR</span><br><span class="hljs-comment">#   NCCL_INCLUDE_DIR</span><br><span class="hljs-comment">#     specify where nccl is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   NVTOOLSEXT_PATH (Windows only)</span><br><span class="hljs-comment">#     specify where nvtoolsext is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   ACL_ROOT_DIR</span><br><span class="hljs-comment">#     specify where Compute Library is installed</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   LIBRARY_PATH</span><br><span class="hljs-comment">#   LD_LIBRARY_PATH</span><br><span class="hljs-comment">#     we will search for libraries in these paths</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   ATEN_THREADING</span><br><span class="hljs-comment">#     ATen parallel backend to use for intra- and inter-op parallelism</span><br><span class="hljs-comment">#     possible values:</span><br><span class="hljs-comment">#       OMP - use OpenMP for intra-op and native backend for inter-op tasks</span><br><span class="hljs-comment">#       NATIVE - use native thread pool for both intra- and inter-op tasks</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_SYSTEM_LIBS (work in progress)</span><br><span class="hljs-comment">#      Use system-provided libraries to satisfy the build dependencies.</span><br><span class="hljs-comment">#      When turned on, the following cmake variables will be toggled as well:</span><br><span class="hljs-comment">#        USE_SYSTEM_CPUINFO=ON USE_SYSTEM_SLEEF=ON BUILD_CUSTOM_PROTOBUF=OFF</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_MIMALLOC</span><br><span class="hljs-comment">#      Static link mimalloc into C10, and use mimalloc in alloc_cpu &amp; alloc_free.</span><br><span class="hljs-comment">#      By default, It is only enabled on Windows.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   USE_PRIORITIZED_TEXT_FOR_LD</span><br><span class="hljs-comment">#      Uses prioritized text form cmake/prioritized_text.txt for LD</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BUILD_LIBTORCH_WHL</span><br><span class="hljs-comment">#      Builds libtorch.so and its dependencies as a wheel</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#   BUILD_PYTHON_ONLY</span><br><span class="hljs-comment">#      Builds pytorch as a wheel using libtorch.so from a seperate wheel</span><br></code></pre></td></tr></table></figure><p>最后编译成功后，可以导入torch试试。</p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202406161343241.png" alt="image-20240616131408327"></p><blockquote><p>遇到报错：<strong>ImportError: {path}&#x2F;libstdc++.so.6: version &#96;GLIBCXX_3.4.30’ not found</strong></p><p>先检查下&#x2F;usr&#x2F;lib下的库支不支持该版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">&gt;</span><span class="language-bash">strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX</span><br></code></pre></td></tr></table></figure><p>如果存在：</p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202406161343285.png" alt="image-20240616131923931"></p><p>则把&#x2F;usr&#x2F;lib下的这个库替换到报错的{path}中。</p></blockquote>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>TailQ链表队列</title>
    <link href="/2024/03/24/TailQ%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97/"/>
    <url>/2024/03/24/TailQ%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97/</url>
    
    <content type="html"><![CDATA[<h1 id="0、零零零"><a href="#0、零零零" class="headerlink" title="0、零零零"></a>0、零零零</h1><p>最近在看iperf3的源码，发现使用了TailQ作为维护不同协议结构的链表。想到之前在工作中使用tailQ还引发了一些bug，觉得有必要好好整理一下tailQ的相关细节。</p><p>TailQ是一个双向链表，虽然双向链表是一个比较基础的数据结构，但是TailQ的设计还是十分精巧的，既有相当灵活和泛用的使用场景，又不依赖于linux惯用的container_of宏获取节点数据，这个设计思路值得好好琢磨琢磨。</p><h1 id="1、TailQ结构"><a href="#1、TailQ结构" class="headerlink" title="1、TailQ结构"></a>1、TailQ结构</h1><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403241501455.svg" alt="tailq_struct"></p><p>TailQ由一个list head和若干list node两种结构组成：</p><h3 id="TAILQ-HEAD"><a href="#TAILQ-HEAD" class="headerlink" title="TAILQ_HEAD"></a>TAILQ_HEAD</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_HEAD(name, type)                                    \</span><br><span class="hljs-meta">struct name &#123;                                                     \</span><br><span class="hljs-meta">struct type *tqh_first; <span class="hljs-comment">/* first element */</span>                     \</span><br><span class="hljs-meta">struct type **tqh_last; <span class="hljs-comment">/* addr of last next element */</span>         \</span><br><span class="hljs-meta">&#125;                                                              </span><br></code></pre></td></tr></table></figure><p>宏展开后：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">name</span> </span><br><span class="hljs-class">&#123;</span> <br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">type</span> *<span class="hljs-title">tqh_first</span>;</span> <br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">type</span> **<span class="hljs-title">tqh_last</span>;</span>  <br>&#125; <br></code></pre></td></tr></table></figure><p>该宏定义的是TailQ的list head，链表头中有两个type指针。在使用的时候，name是这个tailQ头结构的名字，而type则是链表节点的类型名。尤其要注意的是，thq_last与tqh_first不同，它是一个二重指针，从这里就能看出tailQ和最常见的双向链表不一样，分析使用接口的时候才能更深切的体会其奥妙。</p><h3 id="TAILQ-ENTRY"><a href="#TAILQ-ENTRY" class="headerlink" title="TAILQ_ENTRY"></a>TAILQ_ENTRY</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_ENTRY(type)                                         \</span><br><span class="hljs-meta">struct &#123;                                                          \</span><br><span class="hljs-meta">struct type *tqe_next;  <span class="hljs-comment">/* next element */</span>                      \</span><br><span class="hljs-meta">struct type **tqe_prev; <span class="hljs-comment">/* address of previous next element */</span>  \</span><br><span class="hljs-meta">&#125;  </span><br></code></pre></td></tr></table></figure><p>该宏展开后：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span> <br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">type</span> *<span class="hljs-title">tqe_next</span>;</span> <br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">type</span> **<span class="hljs-title">tqe_prev</span>;</span>  <br>&#125; <br></code></pre></td></tr></table></figure><p>该宏定义的是tailQ节点的结构，和tailQ头的定义对比，可以发现head节点和node节点的结构除了变量名之外是大差不差的。所以head和node节点在经过类型转换后，都可以操作tqh_last指针或tqe_next指针，其效果是一样的，在接口中经常有这两种结构的复用操作。</p><p>定义了结构以后，链表还需要初始化，我们看下tailQ的初始化接口。</p><h3 id="TAILQ-INIT"><a href="#TAILQ-INIT" class="headerlink" title="TAILQ_INIT"></a>TAILQ_INIT</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_INIT(head) do &#123;                                     \</span><br><span class="hljs-meta">TAILQ_FIRST((head)) = NULL;                                     \</span><br><span class="hljs-meta">(head)-&gt;tqh_last = &amp;TAILQ_FIRST((head));                        \</span><br><span class="hljs-meta">&#125; while (0)</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_FIRST(head)       ((head)-&gt;tqh_first)</span><br></code></pre></td></tr></table></figure><p>该宏展开后：</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs livescript"><span class="hljs-keyword">do</span> &#123; <br>  <span class="hljs-function"><span class="hljs-params">(((head))-&gt;tqh_first)</span> = <span class="hljs-params">((<span class="hljs-literal">void</span>*)<span class="hljs-number">0</span>)</span>; </span><br><span class="hljs-function">  <span class="hljs-params">(head)</span>-&gt;</span>tqh_last = &amp;<span class="hljs-function"><span class="hljs-params">(((&amp;testp-&gt;xbind_addrs))-&gt;tqh_first)</span>; </span><br><span class="hljs-function">&#125; <span class="hljs-title">while</span> <span class="hljs-params">(<span class="hljs-number">0</span>)</span></span><br></code></pre></td></tr></table></figure><p>这个操作很好理解，将队列头的first指针置为NULL，last指针指向first域（这就是二级指针的原因，其指向了一个指针），初始化完的链表就如图中所示的空列表状态。</p><p>那列表中如果有其他节点是什么样的状态呢？看图中下面的列表，其有一个列表头和3个节点。我们发现数据不是在tailQ节点结构中的，而是tailQ节点被数据的结构体包含着，这样做的原因是增强数据结构的灵活性和泛用性，linux的大量数据结构都是这么定义的。但tailQ的定义方式与linux的一些数据结构定义还有所不同，没有与数据完全解耦，而是通过给用户开放节点定义的接口，让用户自己把需要的数据包含到节点中。关于这一点想详细了解的同学，可以去翻看linux container_of宏的相关定义。</p><p>根据示意图我们可以总结出tailQ结构的几个特点：</p><ul><li>链表头的tqh_first指针指向列表中第一个节点；链表头的tqh_last指针指向列表最后一个节点的tqe_next域；</li><li>节点的tqe_next指针指向下一个节点；节点的tqe_prev指针指向下一个节点的tqe_next域。</li></ul><p>对比一下，链表头和链表节点的结构基本就是一模一样的，其next指针都指向下一个节点，prev指针都指向上一个节点的next域，而链表头则分别连接链表的第一个节点和最后一个节点。我们再分析一下，可以发现一些隐藏的特点：</p><ul><li>一个节点的tqe_prev节点解引用，就是一个指向自己这个节点的一级指针</li></ul><p>这个特点是tailQ很多接口操作的基础，也是其设计最精妙的所在，理解了这个操作就可以很快的明白其他接口的原理。接口分析比较抽象，结合实际用例更好理解。</p><h1 id="2、TailQ接口"><a href="#2、TailQ接口" class="headerlink" title="2、TailQ接口"></a>2、TailQ接口</h1><p>我们先定义实例节点，linux中的数据结构有很多都是这样定义的，把数据结构包在数据实例之内，以增加数据结构的泛用性（一套数据结构可以用于多种实例）和灵活性（一个数据实例可以包含多种数据结构）。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> &#123;</span><br>    <span class="hljs-type">char</span> var;<br>    TAILQ_ENTRY(Node) link;<br>&#125;;<br></code></pre></td></tr></table></figure><p>展开以后就是这副模样：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">Node</span> &#123;</span><br>    <span class="hljs-type">char</span> var;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>      Node *tqe_next;<br>      Node **tqe_prev;<br>    &#125; link;<br>&#125;;<br></code></pre></td></tr></table></figure><p>这时我们再定义链表头，要把定义的实例节点类型传进去</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">TAILQ_HEAD(listhead, Node) list_head;<br></code></pre></td></tr></table></figure><p>展开以后也很简单</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">listhead</span> &#123;</span> <br>    Node * tqh_first; <br>    Node ** tqh_last; <br>&#125; list_head;<br></code></pre></td></tr></table></figure><p>再调用一下初始化接口，一个TailQ链表就定义完成了。但是这个链表还是空的，需要调用插入接口添加数据节点。</p><h3 id="TAILQ-INSERT-TAIL"><a href="#TAILQ-INSERT-TAIL" class="headerlink" title="TAILQ_INSERT_TAIL"></a>TAILQ_INSERT_TAIL</h3><p>这个接口是在链表的尾部插入节点，也就是插在最后面，接口调用方式如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">Node * newNode = (Node *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(Node));<br>TAILQ_INSERT_TAIL(list_head, newNode, link);<br></code></pre></td></tr></table></figure><p>展开后比较容易分析插入操作的原理。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">do</span> &#123; <br>  (newNode)-&gt;link.tqe_next = ((<span class="hljs-type">void</span> *)<span class="hljs-number">0</span>); <br>(newNode)-&gt;link.tqe_prev = (list_head)-&gt;tqh_last; <br>*(list_head)-&gt;tqh_last = (newNode); <br>(list_head)-&gt;tqh_last = &amp;(newNode)-&gt;link.tqe_next; <br>&#125; <span class="hljs-keyword">while</span> (<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>tailQ归根结底是一个双向链表，双向链表插入元素无外乎几个重要操作：</p><ol><li>把前驱节点的后继指针和后继节点的前驱指针接在新节点上；</li><li>新节点的前驱指针和后继指针接上对应的节点。</li></ol><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403241937540.svg" alt="tailq_insert_tail"></p><p>尾插操作可以分为四步：</p><ol><li><p>把新节点的next指针置位NULL，这是插入的常规操作；</p></li><li><p>head的tqh_last指针指向的是最后一个节点的tqe_next指针的位置，因此把它赋值给新节点的tqe_prev，就完成了前驱节点的链接。</p></li><li><p>(list_head)-&gt;tqh_last解引用后，就是最后一个节点的tqe_next指针。以图中的结构为例，(list_head)-&gt;tqh_last的初值是0x04300，*(list_head)-&gt;tqh_last &#x3D; (newNode)操作把newNode的地址赋给了0x04300，也即之前链表里最后一个节点的tqe_next指针。这就完成了后继节点的链接。</p></li><li><p>最后更改head节点的tqh_last指针，还是要指向newNode的tqe_next指针。</p></li></ol><p>在列表末尾插入节点的时间复杂度为O(1)，这就是列表头head存在的意义，不需要从头遍历一遍链表才能找到链表的尾部。</p><h3 id="TAILQ-INSERT-HEAD"><a href="#TAILQ-INSERT-HEAD" class="headerlink" title="TAILQ_INSERT_HEAD"></a>TAILQ_INSERT_HEAD</h3><p>tailQ也同样提供了头插的接口：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">Node * newNode = (Node *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(Node));<br>TAILQ_INSERT_HEAD(list_head, newNode, link);<br></code></pre></td></tr></table></figure><p>展开后：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">do</span> &#123;<br>  <span class="hljs-keyword">if</span> (((newNode)-&gt;link.tqe_next = (list_head)-&gt;tqh_first) != <span class="hljs-literal">NULL</span>)<br>(list_head)-&gt;tqh_first-&gt;link.tqe_prev =&amp;(newNode)-&gt;link.tqe_next;<br><span class="hljs-keyword">else</span><br>(list_head)-&gt;tqh_last = &amp;(newNode)-&gt;link.tqe_next;<br>  (list_head)-&gt;tqh_first = (newNode);<br>(newNode)-&gt;link.tqe_prev = &amp;(list_head)-&gt;tqh_first;<br>&#125; <span class="hljs-keyword">while</span> (<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403241944111.svg" alt="tailq_insert_head"></p><ol><li>新结点的next指针指向list_head的tqh_first指针指向的节点a，节点a也是list中的第一个节点。如果这个指针指向的节点a为NULL，那么新节点是在空列表中插入的第一个节点，也就是最后一个节点，list_head的tqh_last指针需要指向新节点的tqe_next域；如果该列表不为空，那么让第一个节点的tqe_pre指针指向新节点的tqe_next域。</li><li>list_head的tqh_first指针指向新节点，宣布谁是list中的第一个节点；</li><li>新节点的tqe_pre指针要指向list_head的tqh_first域。</li></ol><h3 id="TAILQ-INSERT-BEFORE"><a href="#TAILQ-INSERT-BEFORE" class="headerlink" title="TAILQ_INSERT_BEFORE"></a>TAILQ_INSERT_BEFORE</h3><p>该接口用于在指定节点之前插入新节点。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span>TAILQ_INSERT_BEFORE(listelm, elm, field) do &#123;\</span><br><span class="hljs-meta">(elm)-&gt;field.tqe_prev = (listelm)-&gt;field.tqe_prev;\</span><br><span class="hljs-meta">(elm)-&gt;field.tqe_next = (listelm);\</span><br><span class="hljs-meta">*(listelm)-&gt;field.tqe_prev = (elm);\</span><br><span class="hljs-meta">(listelm)-&gt;field.tqe_prev = &amp;(elm)-&gt;field.tqe_next;\</span><br><span class="hljs-meta">&#125; while (0)</span><br></code></pre></td></tr></table></figure><p>tailQ归根结底还是双向链表，插入删除无非是处理好next和pre指针即可。在listelm前插入elm元素，</p><ol><li>新节点前驱指针指向listelm的前驱，新节点后继指针指向listelm。</li><li>一个节点的tqe_prev解引用就是前驱节点指向本节点的指针，把该节点指向了新节点，也就是前驱节点的next指针指向了新节点。</li><li>listelm的前驱节点指向新节点的next域。</li></ol><h3 id="TAILQ-INSERT-AFTER"><a href="#TAILQ-INSERT-AFTER" class="headerlink" title="TAILQ_INSERT_AFTER"></a>TAILQ_INSERT_AFTER</h3><p>该接口用于在给定节点后面插入新节点。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_INSERT_AFTER(head, listelm, elm, field) do &#123;\</span><br><span class="hljs-meta"><span class="hljs-keyword">if</span> (((elm)-&gt;field.tqe_next = (listelm)-&gt;field.tqe_next) != NULL)\</span><br><span class="hljs-meta">(elm)-&gt;field.tqe_next-&gt;field.tqe_prev =\</span><br><span class="hljs-meta">    &amp;(elm)-&gt;field.tqe_next;\</span><br><span class="hljs-meta"><span class="hljs-keyword">else</span>\</span><br><span class="hljs-meta">(head)-&gt;tqh_last = &amp;(elm)-&gt;field.tqe_next;\</span><br><span class="hljs-meta">(listelm)-&gt;field.tqe_next = (elm);\</span><br><span class="hljs-meta">(elm)-&gt;field.tqe_prev = &amp;(listelm)-&gt;field.tqe_next;\</span><br><span class="hljs-meta">&#125; while (0)</span><br></code></pre></td></tr></table></figure><ol><li>新节点next指向目标节点的next节点。</li><li>在节点后面插入也要处理两种情况，若目标节点是最后一个，那么指向新节点next域的就要是head的tqh_last；若不然，则后继节点的pre指向新节点的next。</li><li>目标节点next指向新节点，新节点pre指向目标节点的next域。</li></ol><h3 id="TAILQ-FOREACH"><a href="#TAILQ-FOREACH" class="headerlink" title="TAILQ_FOREACH"></a>TAILQ_FOREACH</h3><p>这个接口用于正向遍历tailQ。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_FOREACH(var, head, field)\</span><br><span class="hljs-meta">for((var) = TAILQ_FIRST(head);\</span><br><span class="hljs-meta">    (var) != TAILQ_END(head);\</span><br><span class="hljs-meta">    (var) = TAILQ_NEXT(var, field))</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_NEXT(elm, field) ((elm)-&gt;field.tqe_next)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span>TAILQ_END(head)NULL</span><br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span> ((var) = (((head))-&gt;tqh_first); (var) != <span class="hljs-literal">NULL</span>; (var) = (((var))-&gt;filed.tqe_next))<br></code></pre></td></tr></table></figure><p>var是要遍历的列表节点对象，用于存储当前操作的节点；head是目标列表的头节点；filed是列表节点在容器中使用的属性名。</p><h3 id="TAILQ-FOREACH-REVERSE"><a href="#TAILQ-FOREACH-REVERSE" class="headerlink" title="TAILQ_FOREACH_REVERSE"></a>TAILQ_FOREACH_REVERSE</h3><p>这个接口用于反向遍历tailQ。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_FOREACH_REVERSE(var, head, headname, field)\</span><br><span class="hljs-meta">for((var) = TAILQ_LAST(head, headname);\</span><br><span class="hljs-meta">    (var) != TAILQ_END(head);\</span><br><span class="hljs-meta">    (var) = TAILQ_PREV(var, headname, field))</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TAILQ_PREV(elm, headname, field)\</span><br><span class="hljs-meta">(*(((struct headname *)((elm)-&gt;field.tqe_prev))-&gt;tqh_last))</span><br></code></pre></td></tr></table></figure><p>TAILQ_PREV可以理解为pre节点的pre指针再解引用，就是pre节点的pre节点的next指针，解引用后是pre节点的node本体。</p><p>这里有一个地方不是很好理解，就是前向遍历为什么结束判断的TAILQ_END也定义为NULL。其实看tailQ结构图示就很直观了，第一个节点的tqe_prev指针指向list_head，而list_head的last指针指向最后一个节点的tqe_next域，解引用之后正好就是NULL。</p><h1 id="3、使用心得"><a href="#3、使用心得" class="headerlink" title="3、使用心得"></a>3、使用心得</h1><p>tailQ不是线程安全的，这一点上很少会有误用。但是，就算是单线程使用，如果对已经在列表中的元素执行头插，那么正向遍历会有链表成环的风险（如图中橙色的线），反向遍历会有节点被截断丢失，很多时候我们无意中会引发这个问题，在排查的时候最好能尽快反应。</p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403311229394.svg" alt="tailq_dup_head"></p><p>尾插则不会有成环的问题，因为尾插不管正向遍历还是反向遍历，都需要next指针去获得下一个节点，而尾插新节点next指针一定置为了null，所以尾插法只会引起节点丢失。</p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403311308806.svg" alt="tailq_dup_tail"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>第一章</title>
    <link href="/2024/03/08/%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
    <url>/2024/03/08/%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<p><strong>第一篇博文，就贴一张图吧！</strong></p><p><img src="https://picgozz.oss-cn-beijing.aliyuncs.com/img/202403082312389.jpeg" alt="mofang"></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
